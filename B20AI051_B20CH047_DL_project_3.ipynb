{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o60_c2u5p70K"
      },
      "source": [
        "# Fraud Detection Model\n",
        "In this tutorial I will walk you through one of the most important applications in machine learning, I will demonstrate how can construct a high-performance model to detect a credit card fraud by using deep learning model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "b2EDfQLg_r2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e33c82-a28b-4296-a32c-30c288872354"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wBDI0BLsp70N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import Keras, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \\\n",
        "    , fbeta_score, classification_report, confusion_matrix, precision_recall_curve, roc_auc_score \\\n",
        "    , roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gcpFfscNp70P",
        "outputId": "7dc093c7-cf66-4c64-9e5c-e955972d3e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cfe80cf-e9d1-40c9-8146-f4dbbb91c3ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cfe80cf-e9d1-40c9-8146-f4dbbb91c3ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cfe80cf-e9d1-40c9-8146-f4dbbb91c3ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cfe80cf-e9d1-40c9-8146-f4dbbb91c3ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Import the dataset\n",
        "df_full = pd.read_csv('/content/gdrive/MyDrive/creditcard.csv')\n",
        "\n",
        "# Print out first 5 row of the dataset\n",
        "df_full.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UjxB2Qi8p70Q",
        "outputId": "0db196a0-ad9f-46e5-e51e-5958ac948fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Count the number of samples for each class (In this case we have 2 classes)\n",
        "df_full.Class.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HkJWuc99p70R"
      },
      "outputs": [],
      "source": [
        "# It is obvious that this data set is highly unbalance\n",
        "# It Easier to sort the datset by \"class\" for stratified sampling\n",
        "df_full.sort_values(by='Class', ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rZv1VtSSp70R"
      },
      "outputs": [],
      "source": [
        "# Dorp out the eniter \"Time\" coloumn\n",
        "df_full.drop('Time', axis=1, inplace=True)\n",
        "\n",
        "# Assign the first \"3000\" samples to new dataframe\n",
        "df_sample = df_full.iloc[:3000, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bY7o3U-yp70R",
        "outputId": "d26896c5-03d5-4a20-ae0e-eb5b18f4d17e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2508\n",
              "1     492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Count the number of samples for each class again (In this case we have 2 classes)\n",
        "df_sample.Class.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xejUjWt1p70S"
      },
      "outputs": [],
      "source": [
        "shuffle_df = shuffle(df_sample, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lzHZvFJsp70S"
      },
      "outputs": [],
      "source": [
        "# Spilt the dataset into 2 dataframe \"train\" & \"test\"\n",
        "df_train = shuffle_df[0:2400]\n",
        "df_test = shuffle_df[2400:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8J0EK-App70S"
      },
      "outputs": [],
      "source": [
        "# Spilt each dataframe into \"feature\" & \"lable\"\n",
        "train_feature = np.array(df_train.values[:, 0:29])\n",
        "train_label = np.array(df_train.values[:, -1])\n",
        "test_feature = np.array(df_test.values[:, 0:29])\n",
        "test_label = np.array(df_test.values[:, -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GD0t15HSp70T",
        "outputId": "83e9327b-6492-4719-bf2e-7000ba0efd5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "train_feature.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HFXdHSDNp70T",
        "outputId": "736b11c0-f3a0-4c0a-bad1-19015cd4fca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "train_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VqzTOIh-p70T"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_feature)\n",
        "train_feature_trans = scaler.transform(train_feature)\n",
        "test_feature_trans = scaler.transform(test_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6B-PCgqIp70T"
      },
      "outputs": [],
      "source": [
        "\n",
        "def show_train_history(train_history, train, validation):\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(train)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcUrp-CQp70U"
      },
      "source": [
        "# Model overview\n",
        "In this tutorial I will use a **3 fully-connected layers** + **Dropout**, and **ReLu** as activation function, the first layer contains 200 units, the second also with 200 units, and the third with a single output unit. \n",
        "For optimization algorithm, I used **Adam optimization** to optimize the **Accuracy Matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wxwwYJMXp70U",
        "outputId": "9d11b639-e63c-497a-9851-0e1254ef2215",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 200)               6000      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               40200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,401\n",
            "Trainable params: 46,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "1/1 - 7s - loss: 0.6984 - accuracy: 0.2568 - val_loss: 0.6843 - val_accuracy: 0.8360 - 7s/epoch - 7s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 0.6856 - accuracy: 0.7745 - val_loss: 0.6713 - val_accuracy: 0.8360 - 77ms/epoch - 77ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 0.6739 - accuracy: 0.7996 - val_loss: 0.6580 - val_accuracy: 0.8360 - 49ms/epoch - 49ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 0.6620 - accuracy: 0.7996 - val_loss: 0.6433 - val_accuracy: 0.8360 - 59ms/epoch - 59ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 0.6497 - accuracy: 0.7996 - val_loss: 0.6263 - val_accuracy: 0.8360 - 56ms/epoch - 56ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 0.6335 - accuracy: 0.7996 - val_loss: 0.6072 - val_accuracy: 0.8360 - 48ms/epoch - 48ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 0.6166 - accuracy: 0.7996 - val_loss: 0.5860 - val_accuracy: 0.8360 - 59ms/epoch - 59ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 0.5958 - accuracy: 0.7996 - val_loss: 0.5628 - val_accuracy: 0.8360 - 56ms/epoch - 56ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 0.5789 - accuracy: 0.7996 - val_loss: 0.5382 - val_accuracy: 0.8360 - 62ms/epoch - 62ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 0.5586 - accuracy: 0.7996 - val_loss: 0.5132 - val_accuracy: 0.8360 - 58ms/epoch - 58ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 0.5395 - accuracy: 0.7996 - val_loss: 0.4889 - val_accuracy: 0.8360 - 60ms/epoch - 60ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 0.5165 - accuracy: 0.7996 - val_loss: 0.4667 - val_accuracy: 0.8360 - 48ms/epoch - 48ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 0.4994 - accuracy: 0.7996 - val_loss: 0.4480 - val_accuracy: 0.8360 - 60ms/epoch - 60ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 0.4878 - accuracy: 0.7996 - val_loss: 0.4342 - val_accuracy: 0.8360 - 61ms/epoch - 61ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 0.4850 - accuracy: 0.7996 - val_loss: 0.4258 - val_accuracy: 0.8360 - 56ms/epoch - 56ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 0.4783 - accuracy: 0.7996 - val_loss: 0.4223 - val_accuracy: 0.8360 - 55ms/epoch - 55ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 0.4888 - accuracy: 0.7996 - val_loss: 0.4220 - val_accuracy: 0.8360 - 52ms/epoch - 52ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 0.4897 - accuracy: 0.7996 - val_loss: 0.4226 - val_accuracy: 0.8360 - 57ms/epoch - 57ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 0.4824 - accuracy: 0.7996 - val_loss: 0.4225 - val_accuracy: 0.8360 - 57ms/epoch - 57ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 0.4953 - accuracy: 0.7996 - val_loss: 0.4208 - val_accuracy: 0.8360 - 56ms/epoch - 56ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 0.4930 - accuracy: 0.7996 - val_loss: 0.4179 - val_accuracy: 0.8360 - 57ms/epoch - 57ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 0.4901 - accuracy: 0.7996 - val_loss: 0.4143 - val_accuracy: 0.8360 - 58ms/epoch - 58ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 0.4765 - accuracy: 0.7996 - val_loss: 0.4109 - val_accuracy: 0.8360 - 52ms/epoch - 52ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 0.4674 - accuracy: 0.7996 - val_loss: 0.4087 - val_accuracy: 0.8360 - 58ms/epoch - 58ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 0.4683 - accuracy: 0.7996 - val_loss: 0.4078 - val_accuracy: 0.8360 - 59ms/epoch - 59ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 0.4624 - accuracy: 0.7996 - val_loss: 0.4085 - val_accuracy: 0.8360 - 57ms/epoch - 57ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 0.4646 - accuracy: 0.7996 - val_loss: 0.4103 - val_accuracy: 0.8360 - 65ms/epoch - 65ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 0.4546 - accuracy: 0.7996 - val_loss: 0.4122 - val_accuracy: 0.8360 - 60ms/epoch - 60ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 0.4569 - accuracy: 0.7996 - val_loss: 0.4135 - val_accuracy: 0.8360 - 64ms/epoch - 64ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 0.4526 - accuracy: 0.7996 - val_loss: 0.4135 - val_accuracy: 0.8360 - 54ms/epoch - 54ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 0.4548 - accuracy: 0.7996 - val_loss: 0.4117 - val_accuracy: 0.8360 - 52ms/epoch - 52ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 0.4491 - accuracy: 0.7996 - val_loss: 0.4082 - val_accuracy: 0.8360 - 47ms/epoch - 47ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 0.4430 - accuracy: 0.7996 - val_loss: 0.4034 - val_accuracy: 0.8360 - 47ms/epoch - 47ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 0.4462 - accuracy: 0.7996 - val_loss: 0.3978 - val_accuracy: 0.8360 - 47ms/epoch - 47ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 0.4464 - accuracy: 0.7996 - val_loss: 0.3921 - val_accuracy: 0.8360 - 35ms/epoch - 35ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 0.4336 - accuracy: 0.7996 - val_loss: 0.3866 - val_accuracy: 0.8360 - 46ms/epoch - 46ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 0.4262 - accuracy: 0.7996 - val_loss: 0.3814 - val_accuracy: 0.8360 - 49ms/epoch - 49ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 0.4328 - accuracy: 0.7996 - val_loss: 0.3769 - val_accuracy: 0.8360 - 49ms/epoch - 49ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 0.4217 - accuracy: 0.7996 - val_loss: 0.3728 - val_accuracy: 0.8360 - 35ms/epoch - 35ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 0.4230 - accuracy: 0.7996 - val_loss: 0.3690 - val_accuracy: 0.8360 - 52ms/epoch - 52ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 0.4162 - accuracy: 0.7996 - val_loss: 0.3653 - val_accuracy: 0.8360 - 36ms/epoch - 36ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 0.4249 - accuracy: 0.7996 - val_loss: 0.3616 - val_accuracy: 0.8360 - 46ms/epoch - 46ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 0.4085 - accuracy: 0.7996 - val_loss: 0.3579 - val_accuracy: 0.8360 - 48ms/epoch - 48ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 0.4122 - accuracy: 0.8017 - val_loss: 0.3543 - val_accuracy: 0.8360 - 42ms/epoch - 42ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 0.3890 - accuracy: 0.8058 - val_loss: 0.3509 - val_accuracy: 0.8397 - 37ms/epoch - 37ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 0.3887 - accuracy: 0.8142 - val_loss: 0.3477 - val_accuracy: 0.8579 - 158ms/epoch - 158ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 0.4022 - accuracy: 0.8121 - val_loss: 0.3448 - val_accuracy: 0.8621 - 168ms/epoch - 168ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 0.3790 - accuracy: 0.8225 - val_loss: 0.3419 - val_accuracy: 0.8631 - 173ms/epoch - 173ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 0.3906 - accuracy: 0.8225 - val_loss: 0.3385 - val_accuracy: 0.8699 - 188ms/epoch - 188ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 0.3737 - accuracy: 0.8330 - val_loss: 0.3344 - val_accuracy: 0.8699 - 155ms/epoch - 155ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 0.3761 - accuracy: 0.8372 - val_loss: 0.3297 - val_accuracy: 0.8699 - 70ms/epoch - 70ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 0.3671 - accuracy: 0.8413 - val_loss: 0.3246 - val_accuracy: 0.8699 - 101ms/epoch - 101ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 0.3550 - accuracy: 0.8476 - val_loss: 0.3192 - val_accuracy: 0.8719 - 67ms/epoch - 67ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 0.3639 - accuracy: 0.8455 - val_loss: 0.3141 - val_accuracy: 0.8756 - 63ms/epoch - 63ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 0.3514 - accuracy: 0.8518 - val_loss: 0.3090 - val_accuracy: 0.8766 - 80ms/epoch - 80ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 0.3439 - accuracy: 0.8559 - val_loss: 0.3039 - val_accuracy: 0.8792 - 108ms/epoch - 108ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 0.3288 - accuracy: 0.8622 - val_loss: 0.2989 - val_accuracy: 0.8808 - 93ms/epoch - 93ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 0.3358 - accuracy: 0.8622 - val_loss: 0.2939 - val_accuracy: 0.8818 - 62ms/epoch - 62ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 0.3259 - accuracy: 0.8685 - val_loss: 0.2889 - val_accuracy: 0.8855 - 74ms/epoch - 74ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 0.3212 - accuracy: 0.8706 - val_loss: 0.2841 - val_accuracy: 0.8891 - 133ms/epoch - 133ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 0.3200 - accuracy: 0.8706 - val_loss: 0.2793 - val_accuracy: 0.8943 - 95ms/epoch - 95ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 0.3166 - accuracy: 0.8852 - val_loss: 0.2744 - val_accuracy: 0.8980 - 68ms/epoch - 68ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 0.3103 - accuracy: 0.8852 - val_loss: 0.2692 - val_accuracy: 0.9011 - 65ms/epoch - 65ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 0.2910 - accuracy: 0.8852 - val_loss: 0.2634 - val_accuracy: 0.9063 - 86ms/epoch - 86ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 0.2884 - accuracy: 0.8956 - val_loss: 0.2573 - val_accuracy: 0.9073 - 61ms/epoch - 61ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 0.2855 - accuracy: 0.8894 - val_loss: 0.2516 - val_accuracy: 0.9089 - 102ms/epoch - 102ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 0.2845 - accuracy: 0.8873 - val_loss: 0.2460 - val_accuracy: 0.9105 - 70ms/epoch - 70ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 0.2735 - accuracy: 0.9019 - val_loss: 0.2405 - val_accuracy: 0.9151 - 57ms/epoch - 57ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 0.2701 - accuracy: 0.9061 - val_loss: 0.2350 - val_accuracy: 0.9178 - 63ms/epoch - 63ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 0.2655 - accuracy: 0.9019 - val_loss: 0.2296 - val_accuracy: 0.9219 - 52ms/epoch - 52ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 0.2541 - accuracy: 0.9186 - val_loss: 0.2244 - val_accuracy: 0.9245 - 36ms/epoch - 36ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 0.2509 - accuracy: 0.9186 - val_loss: 0.2193 - val_accuracy: 0.9271 - 48ms/epoch - 48ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 0.2413 - accuracy: 0.9290 - val_loss: 0.2142 - val_accuracy: 0.9287 - 35ms/epoch - 35ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 0.2399 - accuracy: 0.9248 - val_loss: 0.2092 - val_accuracy: 0.9328 - 49ms/epoch - 49ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 0.2360 - accuracy: 0.9248 - val_loss: 0.2042 - val_accuracy: 0.9349 - 36ms/epoch - 36ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 0.2264 - accuracy: 0.9374 - val_loss: 0.1994 - val_accuracy: 0.9375 - 35ms/epoch - 35ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.2040 - accuracy: 0.9332 - val_loss: 0.1949 - val_accuracy: 0.9401 - 48ms/epoch - 48ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.2027 - accuracy: 0.9353 - val_loss: 0.1903 - val_accuracy: 0.9412 - 37ms/epoch - 37ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.2013 - accuracy: 0.9395 - val_loss: 0.1861 - val_accuracy: 0.9459 - 46ms/epoch - 46ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.2041 - accuracy: 0.9457 - val_loss: 0.1819 - val_accuracy: 0.9490 - 35ms/epoch - 35ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.1995 - accuracy: 0.9478 - val_loss: 0.1778 - val_accuracy: 0.9505 - 48ms/epoch - 48ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.1981 - accuracy: 0.9374 - val_loss: 0.1739 - val_accuracy: 0.9516 - 48ms/epoch - 48ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.1893 - accuracy: 0.9499 - val_loss: 0.1702 - val_accuracy: 0.9521 - 36ms/epoch - 36ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.1797 - accuracy: 0.9478 - val_loss: 0.1668 - val_accuracy: 0.9526 - 34ms/epoch - 34ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.1801 - accuracy: 0.9520 - val_loss: 0.1635 - val_accuracy: 0.9531 - 46ms/epoch - 46ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.1791 - accuracy: 0.9562 - val_loss: 0.1602 - val_accuracy: 0.9552 - 35ms/epoch - 35ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.1731 - accuracy: 0.9499 - val_loss: 0.1572 - val_accuracy: 0.9563 - 34ms/epoch - 34ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.1687 - accuracy: 0.9562 - val_loss: 0.1546 - val_accuracy: 0.9568 - 47ms/epoch - 47ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.1615 - accuracy: 0.9562 - val_loss: 0.1528 - val_accuracy: 0.9563 - 35ms/epoch - 35ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.1673 - accuracy: 0.9541 - val_loss: 0.1508 - val_accuracy: 0.9568 - 37ms/epoch - 37ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.1640 - accuracy: 0.9541 - val_loss: 0.1479 - val_accuracy: 0.9573 - 35ms/epoch - 35ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.1572 - accuracy: 0.9603 - val_loss: 0.1452 - val_accuracy: 0.9589 - 39ms/epoch - 39ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.1429 - accuracy: 0.9562 - val_loss: 0.1429 - val_accuracy: 0.9599 - 35ms/epoch - 35ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.1431 - accuracy: 0.9603 - val_loss: 0.1411 - val_accuracy: 0.9599 - 34ms/epoch - 34ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.1450 - accuracy: 0.9603 - val_loss: 0.1397 - val_accuracy: 0.9599 - 34ms/epoch - 34ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.1426 - accuracy: 0.9624 - val_loss: 0.1386 - val_accuracy: 0.9599 - 46ms/epoch - 46ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.1401 - accuracy: 0.9624 - val_loss: 0.1373 - val_accuracy: 0.9599 - 49ms/epoch - 49ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.1517 - accuracy: 0.9582 - val_loss: 0.1352 - val_accuracy: 0.9615 - 48ms/epoch - 48ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.1316 - accuracy: 0.9603 - val_loss: 0.1332 - val_accuracy: 0.9625 - 34ms/epoch - 34ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.1362 - accuracy: 0.9624 - val_loss: 0.1318 - val_accuracy: 0.9630 - 51ms/epoch - 51ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.1489 - accuracy: 0.9603 - val_loss: 0.1308 - val_accuracy: 0.9625 - 37ms/epoch - 37ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.1419 - accuracy: 0.9645 - val_loss: 0.1296 - val_accuracy: 0.9625 - 38ms/epoch - 38ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.1231 - accuracy: 0.9645 - val_loss: 0.1286 - val_accuracy: 0.9620 - 35ms/epoch - 35ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.1277 - accuracy: 0.9708 - val_loss: 0.1279 - val_accuracy: 0.9620 - 35ms/epoch - 35ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.1238 - accuracy: 0.9645 - val_loss: 0.1273 - val_accuracy: 0.9620 - 50ms/epoch - 50ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.1232 - accuracy: 0.9645 - val_loss: 0.1255 - val_accuracy: 0.9625 - 48ms/epoch - 48ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.1164 - accuracy: 0.9687 - val_loss: 0.1239 - val_accuracy: 0.9636 - 35ms/epoch - 35ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.1150 - accuracy: 0.9708 - val_loss: 0.1231 - val_accuracy: 0.9641 - 34ms/epoch - 34ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.1246 - accuracy: 0.9687 - val_loss: 0.1228 - val_accuracy: 0.9641 - 34ms/epoch - 34ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.1171 - accuracy: 0.9666 - val_loss: 0.1228 - val_accuracy: 0.9630 - 46ms/epoch - 46ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.1198 - accuracy: 0.9645 - val_loss: 0.1223 - val_accuracy: 0.9636 - 47ms/epoch - 47ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.1140 - accuracy: 0.9708 - val_loss: 0.1218 - val_accuracy: 0.9636 - 47ms/epoch - 47ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.1026 - accuracy: 0.9708 - val_loss: 0.1202 - val_accuracy: 0.9646 - 47ms/epoch - 47ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.0986 - accuracy: 0.9749 - val_loss: 0.1193 - val_accuracy: 0.9646 - 46ms/epoch - 46ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.1002 - accuracy: 0.9729 - val_loss: 0.1189 - val_accuracy: 0.9646 - 33ms/epoch - 33ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.1097 - accuracy: 0.9729 - val_loss: 0.1185 - val_accuracy: 0.9646 - 34ms/epoch - 34ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.1055 - accuracy: 0.9729 - val_loss: 0.1180 - val_accuracy: 0.9646 - 35ms/epoch - 35ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.1088 - accuracy: 0.9708 - val_loss: 0.1175 - val_accuracy: 0.9646 - 35ms/epoch - 35ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.1072 - accuracy: 0.9687 - val_loss: 0.1179 - val_accuracy: 0.9646 - 33ms/epoch - 33ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.1046 - accuracy: 0.9770 - val_loss: 0.1174 - val_accuracy: 0.9646 - 33ms/epoch - 33ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.1016 - accuracy: 0.9729 - val_loss: 0.1164 - val_accuracy: 0.9646 - 34ms/epoch - 34ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.0954 - accuracy: 0.9749 - val_loss: 0.1153 - val_accuracy: 0.9641 - 33ms/epoch - 33ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.0941 - accuracy: 0.9749 - val_loss: 0.1149 - val_accuracy: 0.9646 - 34ms/epoch - 34ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.0962 - accuracy: 0.9729 - val_loss: 0.1146 - val_accuracy: 0.9646 - 34ms/epoch - 34ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.1009 - accuracy: 0.9729 - val_loss: 0.1149 - val_accuracy: 0.9641 - 47ms/epoch - 47ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.0972 - accuracy: 0.9708 - val_loss: 0.1151 - val_accuracy: 0.9641 - 41ms/epoch - 41ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.0940 - accuracy: 0.9729 - val_loss: 0.1144 - val_accuracy: 0.9641 - 34ms/epoch - 34ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.0986 - accuracy: 0.9729 - val_loss: 0.1129 - val_accuracy: 0.9672 - 35ms/epoch - 35ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.1120 - val_accuracy: 0.9682 - 34ms/epoch - 34ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.0909 - accuracy: 0.9749 - val_loss: 0.1120 - val_accuracy: 0.9682 - 47ms/epoch - 47ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.0936 - accuracy: 0.9708 - val_loss: 0.1123 - val_accuracy: 0.9677 - 35ms/epoch - 35ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.0931 - accuracy: 0.9749 - val_loss: 0.1134 - val_accuracy: 0.9672 - 47ms/epoch - 47ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.0986 - accuracy: 0.9749 - val_loss: 0.1140 - val_accuracy: 0.9662 - 46ms/epoch - 46ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.0966 - accuracy: 0.9729 - val_loss: 0.1130 - val_accuracy: 0.9677 - 47ms/epoch - 47ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.0943 - accuracy: 0.9729 - val_loss: 0.1120 - val_accuracy: 0.9682 - 46ms/epoch - 46ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.0900 - accuracy: 0.9791 - val_loss: 0.1110 - val_accuracy: 0.9688 - 33ms/epoch - 33ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.0899 - accuracy: 0.9791 - val_loss: 0.1106 - val_accuracy: 0.9698 - 34ms/epoch - 34ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.0878 - accuracy: 0.9729 - val_loss: 0.1106 - val_accuracy: 0.9698 - 33ms/epoch - 33ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.0816 - accuracy: 0.9770 - val_loss: 0.1110 - val_accuracy: 0.9693 - 37ms/epoch - 37ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.0921 - accuracy: 0.9749 - val_loss: 0.1116 - val_accuracy: 0.9688 - 34ms/epoch - 34ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.0844 - accuracy: 0.9729 - val_loss: 0.1122 - val_accuracy: 0.9682 - 33ms/epoch - 33ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.0850 - accuracy: 0.9791 - val_loss: 0.1126 - val_accuracy: 0.9682 - 48ms/epoch - 48ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.0834 - accuracy: 0.9770 - val_loss: 0.1112 - val_accuracy: 0.9698 - 34ms/epoch - 34ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.0848 - accuracy: 0.9791 - val_loss: 0.1104 - val_accuracy: 0.9693 - 45ms/epoch - 45ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.0847 - accuracy: 0.9812 - val_loss: 0.1103 - val_accuracy: 0.9688 - 46ms/epoch - 46ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.0813 - accuracy: 0.9812 - val_loss: 0.1107 - val_accuracy: 0.9693 - 35ms/epoch - 35ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.0741 - accuracy: 0.9833 - val_loss: 0.1119 - val_accuracy: 0.9693 - 46ms/epoch - 46ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.0840 - accuracy: 0.9770 - val_loss: 0.1116 - val_accuracy: 0.9693 - 41ms/epoch - 41ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.0774 - accuracy: 0.9770 - val_loss: 0.1108 - val_accuracy: 0.9688 - 36ms/epoch - 36ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.0771 - accuracy: 0.9791 - val_loss: 0.1104 - val_accuracy: 0.9703 - 35ms/epoch - 35ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.0791 - accuracy: 0.9812 - val_loss: 0.1104 - val_accuracy: 0.9708 - 34ms/epoch - 34ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.1117 - val_accuracy: 0.9693 - 46ms/epoch - 46ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.0732 - accuracy: 0.9833 - val_loss: 0.1121 - val_accuracy: 0.9693 - 48ms/epoch - 48ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.0730 - accuracy: 0.9749 - val_loss: 0.1117 - val_accuracy: 0.9703 - 50ms/epoch - 50ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.0685 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9703 - 34ms/epoch - 34ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.0736 - accuracy: 0.9812 - val_loss: 0.1109 - val_accuracy: 0.9703 - 34ms/epoch - 34ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.0678 - accuracy: 0.9791 - val_loss: 0.1115 - val_accuracy: 0.9703 - 45ms/epoch - 45ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.0691 - accuracy: 0.9791 - val_loss: 0.1126 - val_accuracy: 0.9708 - 46ms/epoch - 46ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.0761 - accuracy: 0.9812 - val_loss: 0.1141 - val_accuracy: 0.9703 - 36ms/epoch - 36ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.0698 - accuracy: 0.9791 - val_loss: 0.1133 - val_accuracy: 0.9714 - 45ms/epoch - 45ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.0787 - accuracy: 0.9729 - val_loss: 0.1116 - val_accuracy: 0.9714 - 47ms/epoch - 47ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.0716 - accuracy: 0.9812 - val_loss: 0.1113 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.0742 - accuracy: 0.9812 - val_loss: 0.1116 - val_accuracy: 0.9714 - 35ms/epoch - 35ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.0668 - accuracy: 0.9812 - val_loss: 0.1124 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.0701 - accuracy: 0.9833 - val_loss: 0.1138 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.0705 - accuracy: 0.9791 - val_loss: 0.1129 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.0749 - accuracy: 0.9770 - val_loss: 0.1115 - val_accuracy: 0.9714 - 37ms/epoch - 37ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.0734 - accuracy: 0.9833 - val_loss: 0.1111 - val_accuracy: 0.9714 - 37ms/epoch - 37ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.0785 - accuracy: 0.9812 - val_loss: 0.1116 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.0660 - accuracy: 0.9833 - val_loss: 0.1126 - val_accuracy: 0.9714 - 52ms/epoch - 52ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.0723 - accuracy: 0.9812 - val_loss: 0.1142 - val_accuracy: 0.9719 - 54ms/epoch - 54ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.0764 - accuracy: 0.9833 - val_loss: 0.1144 - val_accuracy: 0.9714 - 36ms/epoch - 36ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.0721 - accuracy: 0.9812 - val_loss: 0.1132 - val_accuracy: 0.9719 - 47ms/epoch - 47ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.0623 - accuracy: 0.9833 - val_loss: 0.1122 - val_accuracy: 0.9719 - 48ms/epoch - 48ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.0733 - accuracy: 0.9791 - val_loss: 0.1119 - val_accuracy: 0.9714 - 35ms/epoch - 35ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.1122 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.0690 - accuracy: 0.9854 - val_loss: 0.1134 - val_accuracy: 0.9719 - 47ms/epoch - 47ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.0725 - accuracy: 0.9812 - val_loss: 0.1152 - val_accuracy: 0.9719 - 50ms/epoch - 50ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.0681 - accuracy: 0.9812 - val_loss: 0.1168 - val_accuracy: 0.9714 - 45ms/epoch - 45ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.0674 - accuracy: 0.9833 - val_loss: 0.1170 - val_accuracy: 0.9714 - 51ms/epoch - 51ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.0685 - accuracy: 0.9812 - val_loss: 0.1147 - val_accuracy: 0.9719 - 35ms/epoch - 35ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.0699 - accuracy: 0.9854 - val_loss: 0.1133 - val_accuracy: 0.9719 - 46ms/epoch - 46ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.0658 - accuracy: 0.9812 - val_loss: 0.1129 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.0702 - accuracy: 0.9833 - val_loss: 0.1130 - val_accuracy: 0.9714 - 35ms/epoch - 35ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.0698 - accuracy: 0.9812 - val_loss: 0.1138 - val_accuracy: 0.9719 - 35ms/epoch - 35ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.0708 - accuracy: 0.9854 - val_loss: 0.1162 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.1173 - val_accuracy: 0.9719 - 35ms/epoch - 35ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.0802 - accuracy: 0.9812 - val_loss: 0.1150 - val_accuracy: 0.9719 - 46ms/epoch - 46ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.0680 - accuracy: 0.9812 - val_loss: 0.1134 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.0663 - accuracy: 0.9875 - val_loss: 0.1135 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.0682 - accuracy: 0.9896 - val_loss: 0.1141 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.0651 - accuracy: 0.9833 - val_loss: 0.1160 - val_accuracy: 0.9719 - 44ms/epoch - 44ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.0647 - accuracy: 0.9833 - val_loss: 0.1177 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.0701 - accuracy: 0.9854 - val_loss: 0.1173 - val_accuracy: 0.9719 - 48ms/epoch - 48ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.0655 - accuracy: 0.9854 - val_loss: 0.1157 - val_accuracy: 0.9724 - 47ms/epoch - 47ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.0617 - accuracy: 0.9833 - val_loss: 0.1146 - val_accuracy: 0.9714 - 35ms/epoch - 35ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.0664 - accuracy: 0.9854 - val_loss: 0.1146 - val_accuracy: 0.9708 - 47ms/epoch - 47ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.0685 - accuracy: 0.9896 - val_loss: 0.1147 - val_accuracy: 0.9714 - 46ms/epoch - 46ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.0667 - accuracy: 0.9812 - val_loss: 0.1152 - val_accuracy: 0.9714 - 34ms/epoch - 34ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.0672 - accuracy: 0.9854 - val_loss: 0.1167 - val_accuracy: 0.9724 - 33ms/epoch - 33ms/step\n"
          ]
        }
      ],
      "source": [
        "  \n",
        "# Constructing the CNN & training phase\n",
        "\n",
        "# Select the type of the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first Dense layer with 200 neuron units and ReLu activation function\n",
        "model.add(Dense(units=200,\n",
        "                input_dim=29,\n",
        "                kernel_initializer='uniform',\n",
        "                activation='relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the second Dense layer with 200 neuron units and ReLu activation function\n",
        "model.add(Dense(units=200,\n",
        "                kernel_initializer='uniform',\n",
        "                activation='relu'))\n",
        "\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the second Dense layer with 1 neuron units and Sigmoid activation function\n",
        "model.add(Dense(units=1,\n",
        "                kernel_initializer='uniform',\n",
        "                activation='sigmoid'))\n",
        "\n",
        "# Print out the model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Configure the learning process by selecting 'Binary cross tropy' as a loss function\n",
        "# 'Adam' as a optimization function, and to optimize the 'Accuracy matrix'  \n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model by pass 'train_feature_trans' as input for X, 'train_lable' as input for y\n",
        "# number of epochs = 200 and batch size = 500\n",
        "train_history = model.fit(x=train_feature_trans, y=train_label,\n",
        "                          validation_split=0.8, epochs=200,\n",
        "                          batch_size=500, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BWAvErEdp70V",
        "outputId": "52f794e4-1d99-454f-c85d-106c6a01a124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "show_train_history(train_history, 'accuracy', 'val_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lEWsT5pep70V",
        "outputId": "c77207d4-052f-4587-cc6d-aafcda16fdd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Print out the loss curves for training and validation sets\n",
        "show_train_history(train_history, 'loss', 'val_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yrJVM-Gdp70V",
        "outputId": "fb20f48b-8ba1-4fa8-f0ee-f85c2e26a686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9800\n",
            "\n",
            "\n",
            "Accuracy= 0.9800000190734863\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluation phase\n",
        "\n",
        "# Use the testing set to evaluate the model\n",
        "scores = model.evaluate(test_feature_trans, test_label)\n",
        "\n",
        "# Print out the accuracy\n",
        "print('\\n')\n",
        "print('Accuracy=', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ubtGMoRSp70W",
        "outputId": "0809ae3d-2563-4614-8c7d-e01a80d37db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 1ms/step\n",
            "Total number of predictions:  600\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAG1CAYAAAClEcD/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1B0lEQVR4nO3deXgUZbr38V9n60BWE0gCCAHZo0EURmlxRoVIgAgqEUUjhGXgBQOIkUVmUCKMBtxAHBDPjGxHUQdFPAIKGBYXAiIIIsgiA0aBBBAhBshe7x8c+kxDgHSnshR8P3PVdSVPLX2Hq8a777ueqrIZhmEIAIAazqu6AwAAoDxIWAAASyBhAQAsgYQFALAEEhYAwBJIWAAASyBhAQAsgYQFALAEEhYAwBJIWNWgf//+uu+++0w9ps1m05IlS0w9JqyPcw1XEhLWefr37y+bzSabzSZfX181adJEY8eOVX5+frXFlJ2drREjRui6666T3W5Xw4YN1aNHD2VkZFRbTBczcuRItWvXTna7XW3btq3ucGo0zrWKycrKUkJCgmrXrq2IiAiNGTNGxcXF1R0WKpFPdQdQE3Xt2lVz585VUVGRNm/erOTkZNlsNk2dOrXKYzlw4IA6duyo0NBQvfjii4qNjVVRUZFWrFihlJQU7dq1q8pjupyBAwdq48aN+u6776o7lBqPc80zJSUlSkhIUFRUlNavX6/Dhw+rX79+8vX11fPPP1/d4aGyGHCRnJxs3HvvvS5jvXr1Mm666SbDMAyjpKTEeP75543GjRsb/v7+Rps2bYxFixY5ty0uLjYGDhzoXN+iRQtj+vTpl/2Mi+nWrZvRoEEDIy8v74J1v/32m/NnScaHH37o/H3s2LFG8+bNjVq1ahlNmjQxJkyYYBQWFjrXb9261bjzzjuNwMBAIygoyLj55puNTZs2GYZhGAcOHDDuueceIzQ01Khdu7YRExNjLFu2rFzxnjNx4kTjxhtvdGufqw3nmufn2vLlyw0vLy8jOzvbOfb6668bwcHBRkFBQbn+XlgPFdZlfP/991q/fr2io6MlSenp6Xrrrbc0e/ZsNW/eXJ9//rkeffRR1a1bV3fccYdKS0t17bXXatGiRQoPD9f69es1ZMgQ1atXTw8++KBbn338+HF9+umneu655xQQEHDB+tDQ0IvuGxQUpHnz5ql+/fravn27Bg8erKCgII0dO1aSlJSUpJtuukmvv/66vL29tXXrVvn6+kqSUlJSVFhYqM8//1wBAQHauXOnAgMD3Yod7uNcK/+5lpmZqdjYWEVGRjrH4uPjNWzYMO3YsUM33XSTW38/LKK6M2ZNk5ycbHh7exsBAQGG3W43JBleXl7G+++/b+Tn5xu1a9c21q9f77LPoEGDjIcffviix0xJSTESExNdPqM833o3btxoSDIWL1582W113rfe87344otGu3btnL8HBQUZ8+bNK3Pb2NhYIy0t7bKfeSlUWJfHueb5uTZ48GCjS5cuLmOnTp0yJBnLly93+3iwBiqsMtx11116/fXXderUKU2bNk0+Pj5KTEzUjh07dPr0ad19990u2xcWFrp8o5s5c6bmzJmjrKwsnTlzRoWFhR5NQDAq8Kqy9957TzNmzNC+ffuUl5en4uJiBQcHO9enpqbqz3/+s/77v/9bcXFx6t27t5o2bSrp7MSJYcOGaeXKlYqLi1NiYqLatGnjcSy4OM41zjWUH7MEyxAQEKBmzZrpxhtv1Jw5c7Rx40a9+eabysvLkyQtW7ZMW7dudS47d+7U+++/L0l69913NXr0aA0aNEgrV67U1q1bNWDAABUWFrodR/PmzWWz2dy+2J2ZmamkpCR1795dS5cu1bfffqu//vWvLjGkpaVpx44dSkhI0OrVqxUTE6MPP/xQkvTnP/9Z//73v9W3b19t375d7du312uvveZ2/Lg8zjXPzrWoqCjl5OS4jJ37PSoqyq2/ARZS3SVeTVNWC2XhwoVGVFSUkZuba9jtdmPBggUX3X/48OFGp06dXMY6d+7s0h5z50J4165d3b4Q/tJLLxnXXXedy7aDBg0yQkJCLvo5ffr0MXr06FHmuqeeesqIjY0tV7zn0BK8PM61C5X3XDs36SInJ8c59sYbbxjBwcFGfn7+ZfeHNVFhlUPv3r3l7e2tN954Q6NHj9YTTzyh+fPna9++fdqyZYtee+01zZ8/X9LZb6rffPONVqxYoT179ujpp5/Wpk2bPP7smTNnqqSkRLfccos++OAD7d27Vz/88INmzJghh8NR5j7NmzdXVlaW3n33Xe3bt08zZsxwfqOVpDNnzmj48OFau3atfvrpJ3311VfatGmTWrduLUkaNWqUVqxYof3792vLli1as2aNc93l/Pjjj9q6dauys7N15swZZ2Xgybf+qxHnWvnOtS5duigmJkZ9+/bVtm3btGLFCk2YMEEpKSmy2+0e/xughqvujFnTXOwbaXp6ulG3bl0jLy/PmD59utGyZUvD19fXqFu3rhEfH2+sW7fOMAzDyM/PN/r372+EhIQYoaGhxrBhw4ynnnrK42+9hmEYhw4dMlJSUozo6GjDz8/PaNCggdGzZ09jzZo1zm103oXwMWPGGOHh4UZgYKDx0EMPGdOmTXN+6y0oKDD69OljNGzY0PDz8zPq169vDB8+3Dhz5oxhGGe/uTdt2tSw2+1G3bp1jb59+xrHjh0rV6x33HGHIemCZf/+/eX+e68WnGsVO9cOHDhgdOvWzahVq5ZRp04d48knnzSKiorK/bfCemyGUYGrrQAAVBFaggAASyBhVaOsrCwFBgZedMnKyqruEF0MHTr0orEOHTq0usPDJXCu4UpAS7AaFRcX68CBAxdd37hxY/n41Jxb5Y4cOaLc3Nwy1wUHBysiIqKKI0J5ca7hSkDCAgBYAi1BAIAlkLAAAJZAwgIAWAIJy6IKCgqUlpamgoKC6g4FVzjONdQUTLqwqNzcXIWEhOjkyZMuT8YGzMa5hpqCCgsAYAkkLACAJZCwAACWUGOuYfn4NajuECzFMAwZpb/L5hUkm81W3eHgCsa55rniwoOmHavo2L9NO5ZvnetMO1ZVqjnPYoFbbDabbN5cAEfl41yrIUpLqjuCakdLEABgCVRYAGAFRml1R1DtSFgAYAWlJCxaggAAS6DCAgALMGgJkrAAwBJoCdISBABYAwkLAKzAKDVvcUNaWtrZe/H+Y2nVqpVzfX5+vlJSUhQeHq7AwEAlJiYqJyfH5RhZWVlKSEhQ7dq1FRERoTFjxqi4uNjtfwJaggBgBdV44/D111+vzz77zPm7j8//pY4nnnhCy5Yt06JFixQSEqLhw4erV69e+uqrryRJJSUlSkhIUFRUlNavX6/Dhw+rX79+8vX11fPPP+9WHCQsAMAl+fj4KCoq6oLxkydP6s0339TChQvVqVMnSdLcuXPVunVrbdiwQR06dNDKlSu1c+dOffbZZ4qMjFTbtm01efJkjRs3TmlpafLz8yt3HLQEAcAKqqklKEl79+5V/fr1dd111ykpKUlZWVmSpM2bN6uoqEhxcXHObVu1aqVGjRopMzNTkpSZmanY2FhFRkY6t4mPj1dubq527NjhVhxUWABgBSbOEiwoKLjgDdJ2u112u/2CbW+99VbNmzdPLVu21OHDh/Xss8/qj3/8o77//ntlZ2fLz89PoaGhLvtERkYqOztbkpSdne2SrM6tP7fOHVRYAHCVSU9PV0hIiMuSnp5e5rbdunVT79691aZNG8XHx2v58uU6ceKE/vWvf1Vx1CQsALAEwyg1bRk/frxOnjzpsowfP75ccYSGhqpFixb68ccfFRUVpcLCQp04ccJlm5ycHOc1r6ioqAtmDZ77vazrYpdCwgIAKygtNW2x2+0KDg52WcpqB5YlLy9P+/btU7169dSuXTv5+voqIyPDuX737t3KysqSw+GQJDkcDm3fvl1HjhxxbrNq1SoFBwcrJibGrX8CrmEBAC5q9OjR6tGjh6Kjo3Xo0CFNnDhR3t7eevjhhxUSEqJBgwYpNTVVYWFhCg4O1ogRI+RwONShQwdJUpcuXRQTE6O+ffvqhRdeUHZ2tiZMmKCUlJRyJ8lzSFgAYAXV9CzBX375RQ8//LB+/fVX1a1bV7fffrs2bNigunXrSpKmTZsmLy8vJSYmqqCgQPHx8Zo1a5Zzf29vby1dulTDhg2Tw+FQQECAkpOTNWnSJLdjsRmGYZj2l1WAj1+D6g4BAExVXHjQtGMV7Fpn2rHsre4w7VhViWtYAABLoCUIAFbA60VIWABgCbxehJYgAMAaqLAAwApoCZKwAMASaAnSEgQAWAMVFgBYgGFU3wscawoSFgBYAdewaAkCAKyBCgsArIBJFyQsALAEWoK0BAEA1kCFBQBWUMosQRIWAFgBLUFaggAAa6DCAgArYJYgCQsALIGWIC1BAIA1UGEBgBXQEiRhAYAlkLBoCQIArIEKCwAsgNeLkLAAwBpoCdISBABYAxUWAFgB92GRsADAEmgJ0hIEAFgDFRYAWAEtQRIWAFgCLUFaggAAa6DCAgAroCVIwgIAS6AlSEsQAGANVFgAYAVUWCQsALAErmHREgQAWAMVFgBYAS1B8yusffv2qVOnTmYfFgCubkapeYtFmZ6w8vLytG7dOrMPCwC4yrndEpwxY8Yl1x88eNDjYAAAF0FL0P2ENWrUKNWrV09+fn5lri8sLKxwUACA81i4lWcWtxNWdHS0pk6dqgcffLDM9Vu3blW7du0qHBgAAP/J7WtY7dq10+bNmy+63mazyTCMCgUFADhPaal5i0W5XWFNmjRJp0+fvuj6mJgY7d+/v0JBAQDOY+FEYxa3K6yYmBi1b9/+out9fX0VHR3t/P2rr75SQUGBZ9EBAPC/Kv1JF926dWPmIABUlGGYt1hUpT/pgutZAGACWoI8SxAAYA08SxAArIAKi4QFAJbAjcOV3xK02WyV/REAgKsAky4AwApoCVZ+wvr9998r+yMA4MrHl3/PW4I5OTnq27ev6tevLx8fH3l7e7ssAACYyeMKq3///srKytLTTz+tevXqca0KACoTLUHPE9aXX36pL774Qm3btjUxHABAmUhYnrcEGzZsyIQKAECV8ThhTZ8+XU899ZQOHDhgYjgAgDIZpeYtFuVxS/Chhx7S6dOn1bRpU9WuXVu+vr4u648fP17h4AAAZxmldLQ8TljTp083MQwAAC7N44SVnJxsZhwAgEth0kXFbhwuKSnRkiVL9MMPP0iSrr/+evXs2ZP7sADAbBa+9mQWjxPWjz/+qO7du+vgwYNq2bKlJCk9PV0NGzbUsmXL1LRpU9OCBADA41mCI0eOVNOmTfXzzz9ry5Yt2rJli7KystSkSRONHDnSzBgBAKWGeUsFTJkyRTabTaNGjXKO5efnKyUlReHh4QoMDFRiYqJycnJc9svKylJCQoJq166tiIgIjRkzRsXFxW59tscV1rp167RhwwaFhYU5x8LDwzVlyhR17NjR08MCAMpSA65hbdq0SW+88YbatGnjMv7EE09o2bJlWrRokUJCQjR8+HD16tVLX331laSzl48SEhIUFRWl9evX6/Dhw+rXr598fX31/PPPl/vzPa6w7HZ7mQ+2zcvLk5+fn6eHBQDUQHl5eUpKStI//vEPXXPNNc7xkydP6s0339Qrr7yiTp06qV27dpo7d67Wr1+vDRs2SJJWrlypnTt36q233lLbtm3VrVs3TZ48WTNnzlRhYWG5Y/A4Yd1zzz0aMmSINm7cKMMwZBiGNmzYoKFDh6pnz56eHhYAUJbSUtOWgoIC5ebmuiwFBQWX/PiUlBQlJCQoLi7OZXzz5s0qKipyGW/VqpUaNWqkzMxMSVJmZqZiY2MVGRnp3CY+Pl65ubnasWNHuf8JPE5YM2bMUNOmTeVwOOTv7y9/f3917NhRzZo106uvvurpYQEAZTEM05b09HSFhIS4LOnp6Rf96HfffVdbtmwpc5vs7Gz5+fkpNDTUZTwyMlLZ2dnObf4zWZ1bf25deXl8DSs0NFQfffSR9u7dq127dkmSWrdurWbNmnl6SABAFRg/frxSU1Ndxux2e5nb/vzzz3r88ce1atUq+fv7V0V4F+VxhXVO8+bN1aNHD/Xo0YNkVYWGDU3Wj3s2KC93n9Z/+bH+0L5tdYeEKxTnWg1hYkvQbrcrODjYZblYwtq8ebOOHDmim2++WT4+PvLx8dG6des0Y8YM+fj4KDIyUoWFhTpx4oTLfjk5OYqKipIkRUVFXTBr8Nzv57YpD7cqrNTUVE2ePFkBAQEXZOfzvfLKK+4cGm7o3bunXnpxoh5LeUpfb/pWI0f8WcuXva2YG/6ko0d/re7wcAXhXKtBqulZgp07d9b27dtdxgYMGKBWrVpp3LhxatiwoXx9fZWRkaHExERJ0u7du5WVlSWHwyFJcjgceu6553TkyBFFRERIklatWqXg4GDFxMSUOxa3Eta3336roqIi58+oHk88Plj/fHOh5i/4lyTpsZSn1L1bZw3o30cvvDizmqPDlYRzDUFBQbrhhhtcxgICAhQeHu4cHzRokFJTUxUWFqbg4GCNGDFCDodDHTp0kCR16dJFMTEx6tu3r1544QVlZ2drwoQJSklJuWhlVxa3EtaaNWvK/BlVx9fXVzff3EZTXvi7c8wwDGWs/lIdOrSrxshwpeFcq2Fq8KOZpk2bJi8vLyUmJqqgoEDx8fGaNWuWc723t7eWLl2qYcOGyeFwKCAgQMnJyZo0aZJbn+PxpIuBAwfq1VdfVVBQkMv4qVOnNGLECM2ZM8fTQ+MS6tQJk4+Pj47kHHMZP3LkqFq15HFYMA/nWg1Tg14vsnbtWpff/f39NXPmTM2cefGqOzo6WsuXL6/Q53o86WL+/Pk6c+bMBeNnzpzRggULLrlvWfcA8PZiAMCluF1hnUsuhmHo999/d5nmWFJSouXLlzsvql1Menq6nn32WZcxm1egbN7B7oZz1Tl27LiKi4sVEVnHZTwioq6yc45WU1S4EnGu1SxGDXg0U3Vzu8IKDQ1VWFiYbDabWrRooWuuuca51KlTRwMHDlRKSsoljzF+/HidPHnSZbF5BV1yH5xVVFSkLVu+U6e7bneO2Ww2dbrrdm3YsLkaI8OVhnOthqkhD7+tTm5XWGvWrJFhGOrUqZM++OADl4ff+vn5KTo6WvXr17/kMex2+wUzQ2w2m7uhXLWmvfoPzX1zmjZv+U6bNn2rkSMGKyCglubNf6+6Q8MVhnMNNYnbCeuOO+6QJO3fv1+NGjUi0VSDRYv+R3XrhCntmdGKiqqrbdt2KOGeR3XkyLHL7wy4gXOtBqnBswSris3wcLbD3LlzFRgYqN69e7uML1q0SKdPn1ZycrJbx/Pxa+BJGABQYxUXHjTtWKcmJZl2rIBn3jbtWFXJ41mC6enpqlOnzgXjERERbr3fBACA8vD4Pqxzbxc+X3R0tLKysioUFADgPMwS9LzCioiI0HfffXfB+LZt2xQeHl6hoAAA52GWoOcJ6+GHH9bIkSO1Zs0alZSUqKSkRKtXr9bjjz+uPn36mBkjAACetwQnT56sAwcOqHPnzvLxOXuY0tJS9evXj2tYAGA2Zgl6PkvwnD179mjbtm2qVauWYmNjFR0d7dFxmCUI4Epj6izBv/a+/EblFPDcItOOVZU8rrDOadGihVq0aGFGLAAAXBQvcAQAC+BZgpX0AkeefgEAJrPw7D6z8AJHAIAlVPgaFgCgClBhuZewevXqVe5tFy9e7HYwAICLYFq7ezcOh4SEOJfg4GBlZGTom2++ca7fvHmzMjIyFBISYnqgAICrm1sV1ty5c50/jxs3Tg8++KBmz54tb29vSWffOPzYY48pOJg3BwOAqWgJen7jcN26dfXll1+qZcuWLuO7d+/Wbbfdpl9//dWt43HjMIArjZk3Dv8+qodpxwqa/rFpx6pKHj9LsLi4WLt27bpgfNeuXSrlfgEAgMk8niU4YMAADRo0SPv27dMtt9wiSdq4caOmTJmiAQMGmBYgAEC0BFWBhPXSSy8pKipKL7/8sg4fPixJqlevnsaMGaMnn3zStAABAOJ9WDLh4beSlJubK0kVmmzBNSwAVxpTr2EN727asYL+vty0Y1Ulj69hSWevY3322Wd65513nI9jOnTokPLy8kwJDgDwv3iBo+ctwZ9++kldu3ZVVlaWCgoKdPfddysoKEhTp05VQUGBZs+ebWacAHB1s3CiMYvHFdbjjz+u9u3b67ffflOtWrWc4/fff78yMjJMCQ4AgHM8rrC++OILrV+/Xn5+fi7jjRs31sGD5vVtAQCSCdMNLM/jhFVaWqqSkpILxn/55RcFBQVVKCgAwHloCXreEuzSpYumT5/u/N1msykvL08TJ05U9+7mzWYBAECq4H1YXbt2VUxMjPLz8/XII49o7969qlOnjt555x0zYwQAUGF5nrAaNmyobdu26b333tO2bduUl5enQYMGKSkpyWUSBgCg4gwSlmcJq6ioSK1atdLSpUuVlJSkpKQks+MCAMCFRwnL19dX+fn5ZscCALgYKizPJ12kpKRo6tSpKi4uNjMeAEBZSk1cLMrja1ibNm1SRkaGVq5cqdjYWAUEBLisX7x4cYWDAwDgHI8TVmhoqBITE82MBQBwEUy68CBhlZaW6sUXX9SePXtUWFioTp06KS0tjZmBAFCZSFjuX8N67rnn9Je//EWBgYFq0KCBZsyYoZSUlMqIDQAAJ7cT1oIFCzRr1iytWLFCS5Ys0ccff6y3335bpbxcDAAqD5Mu3E9YWVlZLo9eiouLk81m06FDh0wNDADwf4xSw7TFqtxOWMXFxfL393cZ8/X1VVFRkWlBAQBwPrcnXRiGof79+8tutzvH8vPzNXToUJep7UxrBwATWbiVZxa3E1ZycvIFY48++qgpwQAAymblVp5Z3E5Yc+fOrYw4AAC4JI9vHAYAVCFagiQsALACg4Tl+cNvAQCoSlRYAGAFVFgkLACwAlqCtAQBABZBhQUAVkCFRcICACugJUhLEABgEVRYAGABVFgkLACwBBIWLUEAgEVQYQGAFRi26o6g2pGwAMACaAnSEgQAWAQVFgBYgFFKS5CEBQAWQEuQliAA4BJef/11tWnTRsHBwQoODpbD4dAnn3ziXJ+fn6+UlBSFh4crMDBQiYmJysnJcTlGVlaWEhISVLt2bUVERGjMmDEqLi52OxYSFgBYgGHYTFvcce2112rKlCnavHmzvvnmG3Xq1En33nuvduzYIUl64okn9PHHH2vRokVat26dDh06pF69ejn3LykpUUJCggoLC7V+/XrNnz9f8+bN0zPPPOP2v4HNMAzD7b0qgY9fg+oOAQBMVVx40LRj/XJrJ9OOde3G1RXaPywsTC+++KIeeOAB1a1bVwsXLtQDDzwgSdq1a5dat26tzMxMdejQQZ988onuueceHTp0SJGRkZKk2bNna9y4cTp69Kj8/PzK/blUWABwlSkoKFBubq7LUlBQcNn9SkpK9O677+rUqVNyOBzavHmzioqKFBcX59ymVatWatSokTIzMyVJmZmZio2NdSYrSYqPj1dubq6zSisvEhYAWIBRajNtSU9PV0hIiMuSnp5+0c/evn27AgMDZbfbNXToUH344YeKiYlRdna2/Pz8FBoa6rJ9ZGSksrOzJUnZ2dkuyerc+nPr3MEsQQCwADMv3owfP16pqakuY3a7/aLbt2zZUlu3btXJkyf1/vvvKzk5WevWrTMvoHIiYQHAVcZut18yQZ3Pz89PzZo1kyS1a9dOmzZt0quvvqqHHnpIhYWFOnHihEuVlZOTo6ioKElSVFSUvv76a5fjnZtFeG6b8qIlCAAWYGZLsKJKS0tVUFCgdu3aydfXVxkZGc51u3fvVlZWlhwOhyTJ4XBo+/btOnLkiHObVatWKTg4WDExMW59LhUWAFhAdT3pYvz48erWrZsaNWqk33//XQsXLtTatWu1YsUKhYSEaNCgQUpNTVVYWJiCg4M1YsQIORwOdejQQZLUpUsXxcTEqG/fvnrhhReUnZ2tCRMmKCUlxa0qTyJhAQAu4ciRI+rXr58OHz6skJAQtWnTRitWrNDdd98tSZo2bZq8vLyUmJiogoICxcfHa9asWc79vb29tXTpUg0bNkwOh0MBAQFKTk7WpEmT3I6F+7AAoJKYeR/W/hvvNu1YTbatMu1YVYkKCwAsgIffMukCAGARVFgAYAHuPgPwSkTCAgAL4PUitAQBABZBhQUAFlBKS5CEBQBWwDUsWoIAAIugwgIAC+A+LBIWAFhCzXgmUfWiJQgAsAQqLACwAFqCJCwAsASmtdMSBABYBBUWAFgA92GRsADAEpglSEsQAGARVFgAYAFMuiBhAYAlcA2LliAAwCKosADAAph0QcICAEvgGhYtQQCARdSYCuvWui2rOwRcJdZu+2d1hwC4jUkXVFgAAIuoMRUWAODiuIZFwgIAS2CSIC1BAIBFUGEBgAXQEiRhAYAlMEuQliAAwCKosADAAkqrO4AagIQFABZgiJYgLUEAgCVQYQGABZRyIxYJCwCsoJSWIC1BAIA1UGEBgAUw6YKEBQCWwLR2WoIAAIugwgIAC6AlSMICAEugJUhLEABgEVRYAGABVFgkLACwBK5h0RIEAFgEFRYAWEApBRYJCwCsgGcJ0hIEAFgEFRYAWABvFyFhAYAlMK2dliAAwCKosADAAkptTLogYQGABXANi5YgAMAiqLAAwAKYdEHCAgBL4EkXtAQBABZBhQUAFsCjmUhYAGAJzBKkJQgAsAgqLACwACZdkLAAwBKY1k5LEABwCenp6frDH/6goKAgRURE6L777tPu3btdtsnPz1dKSorCw8MVGBioxMRE5eTkuGyTlZWlhIQE1a5dWxERERozZoyKi4vdioWEBQAWYJi4uGPdunVKSUnRhg0btGrVKhUVFalLly46deqUc5snnnhCH3/8sRYtWqR169bp0KFD6tWrl3N9SUmJEhISVFhYqPXr12v+/PmaN2+ennnmGbdisRmGUSMmn3Rs0Km6Q8BVYu22f1Z3CLhK+Na5zrRjvXnto6Yda9Avb3m879GjRxUREaF169bpT3/6k06ePKm6detq4cKFeuCBByRJu3btUuvWrZWZmakOHTrok08+0T333KNDhw4pMjJSkjR79myNGzdOR48elZ+fX7k+mwoLAK4yBQUFys3NdVkKCgrKte/JkyclSWFhYZKkzZs3q6ioSHFxcc5tWrVqpUaNGikzM1OSlJmZqdjYWGeykqT4+Hjl5uZqx44d5Y6bhAUAFlBq4pKenq6QkBCXJT09/fIxlJZq1KhR6tixo2644QZJUnZ2tvz8/BQaGuqybWRkpLKzs53b/GeyOrf+3LryYpYgAFiAmbMEx48fr9TUVJcxu91+2f1SUlL0/fff68svvzQxmvIjYQHAVcZut5crQf2n4cOHa+nSpfr888917bXXOsejoqJUWFioEydOuFRZOTk5ioqKcm7z9ddfuxzv3CzCc9uUBy1BALAAw2be4tbnGoaGDx+uDz/8UKtXr1aTJk1c1rdr106+vr7KyMhwju3evVtZWVlyOBySJIfDoe3bt+vIkSPObVatWqXg4GDFxMSUOxYqLACwgOq6cTglJUULFy7URx99pKCgIOc1p5CQENWqVUshISEaNGiQUlNTFRYWpuDgYI0YMUIOh0MdOnSQJHXp0kUxMTHq27evXnjhBWVnZ2vChAlKSUlxq9IjYQEALur111+XJN15550u43PnzlX//v0lSdOmTZOXl5cSExNVUFCg+Ph4zZo1y7mtt7e3li5dqmHDhsnhcCggIEDJycmaNGmSW7FwHxauOtyHhapi5n1Yf29o3n1Yw3/2/D6s6kSFBQAWUCMqi2rGpAsAgCVQYQGABfB6ERIWAFgCrxehJQgAsAgqLACwACosEhYAWAKzBD1sCe7cuVOPPfaYbrrpJtWrV0/16tXTTTfdpMcee0w7d+40O0YAANyvsD755BPdd999uvnmm3Xvvfc6HxGfk5OjVatW6eabb9ZHH32k+Ph404MFgKsVswQ9SFhPPfWUxo0bV+YjNdLS0pSWlqYxY8aQsADARFzD8qAluGfPHiUlJV10/cMPP6y9e/dWKCgAAM7ndsJq3Lixli1bdtH1y5YtU3R0dIWCAgC4MkxcrMrtluCkSZP0yCOPaO3atYqLi3O5hpWRkaFPP/1UCxcuND1QALialVo61ZjD7YTVu3dvNWjQQDNmzNDLL7/sfDdKVFSUHA6H1q5d63xpFwAAZvHoPqzbbrtNt912W7m2/eqrr9S+fXu3X8cMAPg/TLqogkczdevWTQcPHqzsjwGAKxrXsKogYdWQ90MCACyORzMBgAXQEiRhAYAl8KQLXi8CALCISq+wbDa+FgBARXEfVhUkLCZdAEDF8V/SKkhYv//+e2V/BADgKuDxNaycnBz17dtX9evXl4+Pj7y9vV0WAIB5Sk1crMrjCqt///7KysrS008/rXr16nGtCgAqEdewKpCwvvzyS33xxRdq27atieEAAFA2jxNWw4YNmVABAFWE/9pW4BrW9OnT9dRTT+nAgQMmhgMAKAvXsCpQYT300EM6ffq0mjZtqtq1a8vX19dl/fHjxyscHAAA53icsKZPn25iGACAS2HSRQUSVnJysplxAAAugXRVwRuHS0pKtGTJEv3www+SpOuvv149e/bkPiwAgOk8Tlg//vijunfvroMHD6ply5aSpPT0dDVs2FDLli1T06ZNTQsSAK52Vp4sYRaPZwmOHDlSTZs21c8//6wtW7Zoy5YtysrKUpMmTTRy5EgzYwSAq55h4v+syuMKa926ddqwYYPCwsKcY+Hh4ZoyZYo6duxoSnAAAJzjccKy2+1lPtg2Ly9Pfn5+FQoKAOCKlmAFWoL33HOPhgwZoo0bN8owDBmGoQ0bNmjo0KHq2bOnmTECwFWvVIZpi1V5nLBmzJihpk2byuFwyN/fX/7+/urYsaOaNWumV1991cwYAQDwvCUYGhqqjz76SHv37tWuXbskSa1bt1azZs1MCw4AcJZ16yLzVPgFjs2bN1fz5s3NiAUAcBFWbuWZxa2ElZqaqsmTJysgIECpqamX3PaVV16pUGCQvLy8NOjJZHXpFafwumE6lvOrli/6VPOmv+Xc5o5uf9R9fXuoZZvmCrkmRP27DNbeHfuqMWpYwcw339Lrc952GWvS6Fp9/M4/JEmLPlquZavW6ofdP+rU6TNa/+kiBQcFumy/c/ePemXWHO3YtUdeXl66+86OGjtiiGrXrlVlfweuLm4lrG+//VZFRUXOn1G5Hk3po/v69dTfRk3R/t0H1OrGlvrrK2OVl3tK78/5UJLkX9tf3329Xas/XqunXhpdvQHDUpo1idY/X33e+ft/PqEmP79At9/aXrff2l7TZ8+9YN8jR3/Vnx8fr66d/6S/pj6mvNOnNPXV/9Jfn3tZ056bUCXxX22YJehmwlqzZk2ZP6Ny3ND+en2x4itlZmyUJGX/kqO77+2kmLatnNus+GCVJCnq2shqiRHW5e3trTrhYWWu6/vQ/ZKkr7d8V+b6des3ysfHRxOeTJGX19m5W8+MGa5e/R5T1i+H1Oja+pUT9FXMyjf8msXjWYIDBw4s8z6sU6dOaeDAgRUKCmd9/80Otb/9ZjW87lpJUrOY69Tmlhu0Yc3X1RwZrgRZvxzUXT2T1LX3AI1Lm6rD2UfKvW9hYZF8fX2cyUqS/O12SdKWbTtMjxWQKpCw5s+frzNnzlwwfubMGS1YsOCS+xYUFCg3N9dlKTUoeM/3339/R599tEYL183TugMrNXfFf+lf//xAKz/MqO7QYHFtYlrqb399UrNf+ZueHj1cvxzOUb/HxujUqdPl2v/Wdm3166+/ac7b76uoqEgnc3/XtNfnSJKO/sq78CoDL3D0YJZgbm6u80bh33//Xf7+/s51JSUlWr58uSIiIi55jPT0dD377LMuY9cGNlaj4CbuhnNF69TjTnXp1VlpKc9p/54Dan59Mz3+7GM6lvOrPlm0srrDg4X90fEH588tmzVRbExLdUlM1qerv1Bij/jL7t/sumg9N+FJvfDaP/TqG3Pl5eWlpAfuVXjYNfLyslVm6FctWoIeJKzQ0FDZbDbZbDa1aNHigvU2m+2CZHS+8ePHXzDLML4VT8c4X8rT/09v/f0dZfzP2euF/961X1HXRqrv8EdIWDBVcFCgohs2UNYvh8q9T0KXu5TQ5S4dO/6bavv7SzabFrz3oa6tX68SI8XVzO2EtWbNGhmGoU6dOumDDz5wefitn5+foqOjVb/+pS+42u122f+3332Ol83j7uQVy7+WXaWG67eq0pIS2fgGC5OdPn1GPx88rB5dO7u9b52wayRJi5eukN3PV44/3GR2eJC1W3lmcTth3XHHHZKk/fv3q1GjRrLZ+I9nZflqVaaSRyYp52CO9u8+oBY3NNdDQ3pr2bufOLcJCg1SVIMI1YmsI0lq1LShJOnXI8d1/Ohv1RI3ar4X//4P3dnxVtWPitSRY79q5j/fkre3l7rHnf3/97Ffj+vYr785K669+w4ooHYt1YuKUEhwkCRp4fv/o7axMapdy1+Zm77VyzPf1KhhAy64XwvmOP/L69XI4yddrF69WoGBgerdu7fL+KJFi3T69GklJydXOLir3bQJr2nw2IEa/fwoXRMeqmM5v+qjt5Zq7rT/m9Tyxy636a/Txjl/n/T6M5KkN1+erzmvzK/ymGENOUeOaezEqTqRm6uw0BDd1OZ6vf3GNIVdEypJem/Jcpcbi5NTxkiS/vaXVN2XcLckafsPezTzzbd0+swZNYluqGfGjlBPDyo0oLxshuFZ2m7RooXeeOMN3XXXXS7j69at05AhQ7R79263jtexQSdPwgDctnbbP6s7BFwlfOtcZ9qxHo3uZdqx3vppsWnHqkoeV1jn3i58vujoaGVlZVUoKACAK54lWIH7sCIiIvTddxfeBb9t2zaFh4dXKCgAAM7ncYX18MMPa+TIkQoKCtKf/vQnSWfbgY8//rj69OljWoAAAO7DkiqQsCZPnqwDBw6oc+fO8vE5e5jS0lL169dPzz///GX2BgC4g2ntFUhYfn5+eu+99zR58mRt27ZNtWrVUmxsrKKjo82MDwAASSa8wLFFixZlPvECAGAeJl3wAkcAsASuYVXSCxx5+gUAwGy8wBEALIBJFyZcwwIAVD4PH0p0RXErYfXqVf5HgyxebM1HfwAAaia3ElZISIjzZ8Mw9OGHHyokJETt27eXJG3evFknTpxwK7EBAC6PWYJuPppp7ty5ziUyMlIPPvig9u/fr8WLF2vx4sX697//rT59+qhOnTqVFS8AXJUu99p7dxZ3ff755+rRo4fq168vm82mJUuWuKw3DEPPPPOM6tWrp1q1aikuLk579+512eb48eNKSkpScHCwQkNDNWjQIOXl5bkVh8fPEpwzZ45Gjx4tb29v55i3t7dSU1M1Z84cTw8LAKhhTp06pRtvvFEzZ84sc/0LL7ygGTNmaPbs2dq4caMCAgIUHx+v/Px85zZJSUnasWOHVq1apaVLl+rzzz/XkCFD3IrD40kXxcXF2rVrl1q2bOkyvmvXLpWWMp8FAMxUnfdhdevWTd26dStznWEYmj59uiZMmKB7771XkrRgwQJFRkZqyZIl6tOnj3744Qd9+umn2rRpk/MS0muvvabu3bvrpZdeuuxb6s/xOGENGDBAgwYN0r59+3TLLbdIkjZu3KgpU6ZowIABnh4WAFAGM69hFRQUqKCgwGXMbrfLbre7faz9+/crOztbcXFxzrGQkBDdeuutyszMVJ8+fZSZmanQ0FBnspKkuLg4eXl5aePGjbr//vvL9VkeJ6yXXnpJUVFRevnll3X48GFJUr169TRmzBg9+eSTnh4WAFDJ0tPT9eyzz7qMTZw4UWlpaW4fKzs7W5IUGRnpMh4ZGelcl52drYiICJf1Pj4+CgsLc25THh4nLC8vL40dO1Zjx45Vbm6uJCk4ONjTwwEALsHM+7DGjx9/weP1PKmuqprHky6ks9exPvvsM73zzjvOxzEdOnTI7ZkfAIBLM3OWoN1uV3BwsMviacKKioqSJOXk5LiM5+TkONdFRUXpyJEjLuuLi4t1/Phx5zbl4XHC+umnnxQbG6t7771XKSkpOnr0qCRp6tSpGj16tKeHBQBYSJMmTRQVFaWMjAznWG5urjZu3CiHwyFJcjgcOnHihDZv3uzcZvXq1SotLdWtt95a7s/yuCX4+OOPq3379tq2bZvCw8Od4/fff78GDx7s6WEBAGWozlmCeXl5+vHHH52/79+/X1u3blVYWJgaNWqkUaNG6W9/+5uaN2+uJk2a6Omnn1b9+vV13333SZJat26trl27avDgwZo9e7aKioo0fPhw9enTp9wzBKUKJKwvvvhC69evl5+fn8t448aNdfDgQU8PCwAoQ3U+6eKbb77RXXfd5fz93PWv5ORkzZs3T2PHjtWpU6c0ZMgQnThxQrfffrs+/fRT+fv7O/d5++23NXz4cHXu3FleXl5KTEzUjBkz3IrD44RVWlqqkpKSC8Z/+eUXBQUFeXpYAEANc+edd15y0ofNZtOkSZM0adKki24TFhamhQsXVigOj69hdenSRdOnT3f+brPZlJeXp4kTJ6p79+4VCgoA4MowDNMWq6rQfVhdu3ZVTEyM8vPz9cgjj2jv3r2qU6eO3nnnHTNjBICrHg+/rUDCatiwobZt26b33ntP27ZtU15engYNGqSkpCTVqlXLzBgBAPAsYRUVFalVq1ZaunSpkpKSlJSUZHZcAID/UJ2zBGsKjxKWr6+vy1N4AQCVq9TC157M4vGki5SUFE2dOlXFxcVmxgMAQJk8voa1adMmZWRkaOXKlYqNjVVAQIDL+sWLF1c4OADAWdRXFUhYoaGhSkxMNDMWAMBFMEvQg4RVWlqqF198UXv27FFhYaE6deqktLQ0ZgYCACqV29ewnnvuOf3lL39RYGCgGjRooBkzZiglJaUyYgMA/K9SGaYtVuV2wlqwYIFmzZqlFStWaMmSJfr444/19ttvq7S0tDLiAwCIJ11IHiSsrKwsl0cvxcXFyWaz6dChQ6YGBgDAf3L7GlZxcbHLE3ils/dlFRUVmRYUAMCVlVt5ZnE7YRmGof79+7u8nTI/P19Dhw51mdrOtHYAMA9PuvAgYSUnJ18w9uijj5oSDAAAF+N2wpo7d25lxAEAuAQrT5Ywi8c3DgMAqg7XsCrwLEEAAKoSFRYAWAAtQRIWAFgCLUFaggAAi6DCAgAL4D4sEhYAWAJvHKYlCACwCCosALAAWoIkLACwBFqCtAQBABZBhQUAFkBLkIQFAJZAS5CWIADAIqiwAMACaAmSsADAEmgJ0hIEAFgEFRYAWAAtQRIWAFiCYZRWdwjVjpYgAMASqLAAwAJ4gSMJCwAswWCWIC1BAIA1UGEBgAXQEiRhAYAl0BKkJQgAsAgqLACwAB7NRMICAEvgSRe0BAEAFkGFBQAWwKQLEhYAWALT2mkJAgAsggoLACyAliAJCwAsgWnttAQBABZBhQUAFkBLkIQFAJbALEFaggAAi6DCAgALoCVIwgIAS2CWIC1BAIBFUGEBgAXwtHYSFgBYAi1BWoIAAIugwgIAC2CWIAkLACyBa1i0BAEAFkHCAgALMAzDtMUTM2fOVOPGjeXv769bb71VX3/9tcl/4eWRsADAAqozYb333ntKTU3VxIkTtWXLFt14442Kj4/XkSNHKuEvvTgSFgDgkl555RUNHjxYAwYMUExMjGbPnq3atWtrzpw5VRoHCQsALMAwcXFHYWGhNm/erLi4OOeYl5eX4uLilJmZWZE/yW3MEgSAq0xBQYEKCgpcxux2u+x2+wXbHjt2TCUlJYqMjHQZj4yM1K5duyo1zvPVmIT11cHV1R0CANRYxYUHTTtWWlqann32WZexiRMnKi0tzbTPqAw1JmEBAKrG+PHjlZqa6jJWVnUlSXXq1JG3t7dycnJcxnNychQVFVVpMZaFa1gAcJWx2+0KDg52WS6WsPz8/NSuXTtlZGQ4x0pLS5WRkSGHw1FVIUuiwgIAXEZqaqqSk5PVvn173XLLLZo+fbpOnTqlAQMGVGkcJCwAwCU99NBDOnr0qJ555hllZ2erbdu2+vTTTy+YiFHZbAZPVAQAWADXsAAAlkDCAgBYAgkLAGAJJCwAgCWQsAAAlkDCAgBYAgkLAGAJJCwAgCWQsAAAlkDCAgBYAgkLAGAJJCwAgCX8f+cNXOfEmoG5AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prediction = np.argmax(model.predict(test_feature_trans), axis=1)\n",
        "\n",
        "df_ans = pd.DataFrame({'Real Class': test_label})\n",
        "df_ans['Prediction'] = prediction\n",
        "\n",
        "df_ans['Prediction'].value_counts()\n",
        "\n",
        "df_ans['Real Class'].value_counts()\n",
        "\n",
        "cols = ['Real_Class_1', 'Real_Class_0']  # Gold standard\n",
        "rows = ['Prediction_1', 'Prediction_0']  # Diagnostic tool (our prediction)\n",
        "\n",
        "B1P1 = len(df_ans[(df_ans['Prediction'] == df_ans['Real Class']) & (df_ans['Real Class'] == 1)])\n",
        "B1P0 = len(df_ans[(df_ans['Prediction'] != df_ans['Real Class']) & (df_ans['Real Class'] == 1)])\n",
        "B0P1 = len(df_ans[(df_ans['Prediction'] != df_ans['Real Class']) & (df_ans['Real Class'] == 0)])\n",
        "B0P0 = len(df_ans[(df_ans['Prediction'] == df_ans['Real Class']) & (df_ans['Real Class'] == 0)])\n",
        "\n",
        "conf = np.array([[B1P1, B0P1], [B1P0, B0P0]])\n",
        "df_cm = pd.DataFrame(conf, columns=[i for i in cols], index=[i for i in rows])\n",
        "f, ax = plt.subplots(figsize=(5, 5))\n",
        "sns.heatmap(df_cm, annot=True, ax=ax, fmt='d')\n",
        "\n",
        "# Making x label be on top is common in textbooks.\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "\n",
        "print('Total number of predictions: ', np.sum(conf))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "b-QES6Gsp70W",
        "outputId": "c86a3330-5226-4c9f-e9d9-c203c4722c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of test cases:  600\n",
            "G = gold standard, P = prediction\n",
            "G1P1:  0\n",
            "G0P1:  0\n",
            "G1P0:  81\n",
            "G0P0:  519\n",
            "--------------------------------------------------\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.865\n",
            "False_positive_rate:  0.0\n",
            "False_negative_rate:  1.0\n"
          ]
        }
      ],
      "source": [
        "# Model summary function\n",
        "def model_efficacy(conf):\n",
        "    total_num = np.sum(conf)\n",
        "    sen = conf[0][0] / (conf[0][0] + conf[1][0])\n",
        "    spe = conf[1][1] / (conf[1][0] + conf[1][1])\n",
        "    false_positive_rate = conf[0][1] / (conf[0][1] + conf[1][1])\n",
        "    false_negative_rate = conf[1][0] / (conf[0][0] + conf[1][0])\n",
        "\n",
        "    print('Total number of test cases: ', total_num)\n",
        "    print('G = gold standard, P = prediction')\n",
        "    \n",
        "    # G = gold standard; P = prediction\n",
        "    print('G1P1: ', conf[0][0])\n",
        "    print('G0P1: ', conf[0][1])\n",
        "    print('G1P0: ', conf[1][0])\n",
        "    print('G0P0: ', conf[1][1])\n",
        "    print('--------------------------------------------------')\n",
        "    print('Sensitivity: ', sen)\n",
        "    print('Specificity: ', spe)\n",
        "    print('False_positive_rate: ', false_positive_rate)\n",
        "    print('False_negative_rate: ', false_negative_rate)\n",
        "\n",
        "\n",
        "model_efficacy(conf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparamter tuning \n",
        "##Optuna"
      ],
      "metadata": {
        "id": "Iwk3hFWmDnSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGkXNGzUAmtG",
        "outputId": "f1d86dea-53ee-4d2a-a298-28b8344e300e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import optuna\n",
        "# import tensorflow as tf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def create_model(trial):\n",
        "#     # define the hyperparameters to optimize\n",
        "#     num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "#     num_units = trial.suggest_int('num_units', 32, 256)\n",
        "#     learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
        "#     dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "\n",
        "#     # create a Sequential model\n",
        "#     model = tf.keras.Sequential()\n",
        "#     model.add(Dense(units=200,\n",
        "#                 input_dim=29,\n",
        "#                 kernel_initializer='uniform',\n",
        "#                 activation='relu'))\n",
        "# # Add Dropout to prevent overfitting\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "# # Add the second Dense layer with 200 neuron units and ReLu activation function\n",
        "#     model.add(Dense(units=200,\n",
        "#                 kernel_initializer='uniform',\n",
        "#                 activation='relu'))\n",
        "\n",
        "# # Add Dropout to prevent overfitting\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "# # Add the second Dense layer with 1 neuron units and Sigmoid activation function\n",
        "#     model.add(Dense(units=1,\n",
        "#                 kernel_initializer='uniform',\n",
        "#                 activation='sigmoid'))\n",
        "\n",
        "#     # add the input layer\n",
        "#     # model.add(tf.keras.layers.InputLayer(input_shape=(29,)))\n",
        "\n",
        "#     # add hidden layers\n",
        "#     # for i in range(num_layers):\n",
        "#     #     model.add(tf.keras.layers.Dense(units=num_units, activation='relu'))\n",
        "#     #     model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "#     # add the output layer\n",
        "#     # model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "#     # compile the model\n",
        "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "#                   loss='binary_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "fQYSZZwDADJ-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiDXSh6QDAkE",
        "outputId": "e9097f2b-621d-4913-95f2-8a8399966aed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the search space for the hyperparameters\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "    units = trial.suggest_int('units', 50, 500)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
        "    \n",
        "    # Construct the model based on the hyperparameters\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        model.add(Dense(units=units, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model with the selected learning rate\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    \n",
        "    # Train the model and return the validation accuracy\n",
        "    history = model.fit(x=train_feature_trans, y=train_label, validation_split=0.8, epochs=200, batch_size=500, verbose=0)\n",
        "    return history.history['val_accuracy'][-1]\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print the best hyperparameters and the value of the metric to optimize\n",
        "best_params = study.best_params\n",
        "best_value = study.best_value\n",
        "print(f\"Best params: {best_params}, Best value: {best_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te3XIUs_C96A",
        "outputId": "57bb834e-a91e-418f-ece6-e0631aa22b66"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-05-08 20:27:55,069]\u001b[0m A new study created in memory with name: no-name-8f55188a-9ea9-4810-b5fe-682c02b2e6de\u001b[0m\n",
            "<ipython-input-27-f5de0d3a571c>:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
            "<ipython-input-27-f5de0d3a571c>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:28:06,145]\u001b[0m Trial 0 finished with value: 0.9614784121513367 and parameters: {'n_layers': 1, 'units': 393, 'dropout_rate': 0.11753980727653213, 'learning_rate': 0.001468878877324392}. Best is trial 0 with value: 0.9614784121513367.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:28:27,644]\u001b[0m Trial 1 finished with value: 0.9588755965232849 and parameters: {'n_layers': 1, 'units': 260, 'dropout_rate': 0.31023696190618577, 'learning_rate': 1.1464000299856027e-05}. Best is trial 0 with value: 0.9614784121513367.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:28:38,380]\u001b[0m Trial 2 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 105, 'dropout_rate': 0.2169252063431817, 'learning_rate': 1.1864405702343651e-05}. Best is trial 2 with value: 0.9703279733657837.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:28:49,451]\u001b[0m Trial 3 finished with value: 0.9682456851005554 and parameters: {'n_layers': 3, 'units': 56, 'dropout_rate': 0.140316129954745, 'learning_rate': 0.0020355026602693707}. Best is trial 2 with value: 0.9703279733657837.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:29:00,516]\u001b[0m Trial 4 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 443, 'dropout_rate': 0.36736559222257126, 'learning_rate': 0.00036640159536430357}. Best is trial 4 with value: 0.9708485007286072.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:29:09,639]\u001b[0m Trial 5 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 453, 'dropout_rate': 0.47492362852326464, 'learning_rate': 0.0032762997779777012}. Best is trial 4 with value: 0.9708485007286072.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:29:20,060]\u001b[0m Trial 6 finished with value: 0.9708485007286072 and parameters: {'n_layers': 2, 'units': 86, 'dropout_rate': 0.38308700211060687, 'learning_rate': 3.1687291403056914e-05}. Best is trial 4 with value: 0.9708485007286072.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:29:38,411]\u001b[0m Trial 7 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 255, 'dropout_rate': 0.213753518391772, 'learning_rate': 0.0002568356338387972}. Best is trial 7 with value: 0.9713690876960754.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:29:49,465]\u001b[0m Trial 8 finished with value: 0.9593961238861084 and parameters: {'n_layers': 1, 'units': 248, 'dropout_rate': 0.14989224993181907, 'learning_rate': 0.0010491125603926765}. Best is trial 7 with value: 0.9713690876960754.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:30:10,676]\u001b[0m Trial 9 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 474, 'dropout_rate': 0.31387902378815136, 'learning_rate': 5.3436847337190316e-05}. Best is trial 7 with value: 0.9713690876960754.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:30:21,653]\u001b[0m Trial 10 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 179, 'dropout_rate': 0.21416045906375294, 'learning_rate': 0.0001908265183947889}. Best is trial 7 with value: 0.9713690876960754.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:30:32,736]\u001b[0m Trial 11 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 354, 'dropout_rate': 0.3980279839407991, 'learning_rate': 0.0003671502268039922}. Best is trial 7 with value: 0.9713690876960754.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:30:42,371]\u001b[0m Trial 12 finished with value: 0.9724102020263672 and parameters: {'n_layers': 3, 'units': 332, 'dropout_rate': 0.2474883734304866, 'learning_rate': 0.007819438279384996}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:30:53,451]\u001b[0m Trial 13 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 339, 'dropout_rate': 0.22747958357468281, 'learning_rate': 0.008240170175251195}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:03,535]\u001b[0m Trial 14 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 211, 'dropout_rate': 0.25549532598390995, 'learning_rate': 0.00909321741513271}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:14,064]\u001b[0m Trial 15 finished with value: 0.9698073863983154 and parameters: {'n_layers': 3, 'units': 318, 'dropout_rate': 0.17264434959141142, 'learning_rate': 0.0007569086560497332}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:25,006]\u001b[0m Trial 16 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 157, 'dropout_rate': 0.2596735794186757, 'learning_rate': 0.0001449041435483298}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:35,861]\u001b[0m Trial 17 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 296, 'dropout_rate': 0.18045245416669722, 'learning_rate': 0.0046128714952287184}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:46,971]\u001b[0m Trial 18 finished with value: 0.9567933082580566 and parameters: {'n_layers': 3, 'units': 403, 'dropout_rate': 0.10958747338381039, 'learning_rate': 0.004071576120045151}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:31:58,225]\u001b[0m Trial 19 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 301, 'dropout_rate': 0.17925252185958504, 'learning_rate': 0.004536033943664742}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:32:09,826]\u001b[0m Trial 20 finished with value: 0.9724102020263672 and parameters: {'n_layers': 3, 'units': 403, 'dropout_rate': 0.2693870378617871, 'learning_rate': 0.009623478683225715}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:32:20,177]\u001b[0m Trial 21 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 384, 'dropout_rate': 0.2692797912367647, 'learning_rate': 0.008088904461635215}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:32:29,852]\u001b[0m Trial 22 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 500, 'dropout_rate': 0.1821426810056856, 'learning_rate': 0.003150741184209297}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:32:40,531]\u001b[0m Trial 23 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 356, 'dropout_rate': 0.2765691805722731, 'learning_rate': 0.009974670821041183}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:32:50,754]\u001b[0m Trial 24 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 299, 'dropout_rate': 0.29107079633412114, 'learning_rate': 0.0054443767490275}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:01,189]\u001b[0m Trial 25 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 419, 'dropout_rate': 0.2295997778526856, 'learning_rate': 0.0019521640036548188}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:10,638]\u001b[0m Trial 26 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 366, 'dropout_rate': 0.1891682260704457, 'learning_rate': 0.0053534728691762325}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:20,871]\u001b[0m Trial 27 finished with value: 0.9713690876960754 and parameters: {'n_layers': 2, 'units': 226, 'dropout_rate': 0.24832135362296712, 'learning_rate': 0.00331283190532793}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:32,499]\u001b[0m Trial 28 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 291, 'dropout_rate': 0.3260574797453927, 'learning_rate': 0.0061260570218334975}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:47,335]\u001b[0m Trial 29 finished with value: 0.9614784121513367 and parameters: {'n_layers': 1, 'units': 408, 'dropout_rate': 0.10009810817579204, 'learning_rate': 0.0020616350304749377}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:33:58,434]\u001b[0m Trial 30 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 326, 'dropout_rate': 0.15413005194345633, 'learning_rate': 0.0012689821646289982}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:34:09,175]\u001b[0m Trial 31 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 498, 'dropout_rate': 0.1868907520998904, 'learning_rate': 0.003319594220916029}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:34:18,675]\u001b[0m Trial 32 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 500, 'dropout_rate': 0.19694427051848573, 'learning_rate': 0.006396510524249701}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:34:29,438]\u001b[0m Trial 33 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 430, 'dropout_rate': 0.23890696829956448, 'learning_rate': 0.002667266019108498}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:34:40,503]\u001b[0m Trial 34 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 380, 'dropout_rate': 0.13045219661354257, 'learning_rate': 0.0046861602816726695}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:34:51,586]\u001b[0m Trial 35 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 473, 'dropout_rate': 0.167552906816627, 'learning_rate': 0.0023766503817108527}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:02,666]\u001b[0m Trial 36 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 277, 'dropout_rate': 0.13035629144008615, 'learning_rate': 0.009581690206516998}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:11,771]\u001b[0m Trial 37 finished with value: 0.9703279733657837 and parameters: {'n_layers': 2, 'units': 458, 'dropout_rate': 0.1958987390130623, 'learning_rate': 0.003681111605449274}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:22,869]\u001b[0m Trial 38 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 332, 'dropout_rate': 0.21320504104472074, 'learning_rate': 0.006245453184135786}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:33,683]\u001b[0m Trial 39 finished with value: 0.9604372978210449 and parameters: {'n_layers': 1, 'units': 430, 'dropout_rate': 0.16241225938174167, 'learning_rate': 0.0025274102059206207}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:45,266]\u001b[0m Trial 40 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 266, 'dropout_rate': 0.2408962682628871, 'learning_rate': 0.0017992539465724615}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:35:56,393]\u001b[0m Trial 41 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 358, 'dropout_rate': 0.2843263393459283, 'learning_rate': 0.009952668568916747}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:36:07,504]\u001b[0m Trial 42 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 391, 'dropout_rate': 0.2752053186117015, 'learning_rate': 0.006958127646730954}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:36:17,853]\u001b[0m Trial 43 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 360, 'dropout_rate': 0.30966635240414664, 'learning_rate': 0.004595642538447589}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:36:28,945]\u001b[0m Trial 44 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 308, 'dropout_rate': 0.21217283447110036, 'learning_rate': 0.009754539228698777}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:36:40,049]\u001b[0m Trial 45 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 344, 'dropout_rate': 0.2647524615798562, 'learning_rate': 0.006434551337915327}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:36:50,636]\u001b[0m Trial 46 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 285, 'dropout_rate': 0.14518613290691407, 'learning_rate': 0.0031706281992064465}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:00,289]\u001b[0m Trial 47 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 375, 'dropout_rate': 0.2303898554972703, 'learning_rate': 0.0070253168267526995}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:10,239]\u001b[0m Trial 48 finished with value: 0.9708485007286072 and parameters: {'n_layers': 2, 'units': 454, 'dropout_rate': 0.24971245002555814, 'learning_rate': 0.004396471540775221}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:20,755]\u001b[0m Trial 49 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 230, 'dropout_rate': 0.298256045240463, 'learning_rate': 0.007797914338545159}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:31,699]\u001b[0m Trial 50 finished with value: 0.9718896150588989 and parameters: {'n_layers': 2, 'units': 176, 'dropout_rate': 0.3328275093047254, 'learning_rate': 0.00383673927778062}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:42,790]\u001b[0m Trial 51 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 424, 'dropout_rate': 0.21023528102589661, 'learning_rate': 0.0016231597750441084}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:37:54,553]\u001b[0m Trial 52 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 406, 'dropout_rate': 0.23221874299644438, 'learning_rate': 0.0027862209806497865}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:06,093]\u001b[0m Trial 53 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 471, 'dropout_rate': 0.27393264367582226, 'learning_rate': 0.005179694471170883}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:17,593]\u001b[0m Trial 54 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 414, 'dropout_rate': 0.22425031969023873, 'learning_rate': 0.001910032939449986}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:28,704]\u001b[0m Trial 55 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 343, 'dropout_rate': 0.174190542234549, 'learning_rate': 0.007067639509288215}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:39,600]\u001b[0m Trial 56 finished with value: 0.9698073863983154 and parameters: {'n_layers': 3, 'units': 440, 'dropout_rate': 0.2445407885252961, 'learning_rate': 0.005265747701675065}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:50,271]\u001b[0m Trial 57 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 312, 'dropout_rate': 0.2540071460942116, 'learning_rate': 0.001084574498001023}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:38:59,954]\u001b[0m Trial 58 finished with value: 0.9682456851005554 and parameters: {'n_layers': 3, 'units': 396, 'dropout_rate': 0.20090445546389002, 'learning_rate': 0.00811325705306561}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:39:10,525]\u001b[0m Trial 59 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 125, 'dropout_rate': 0.18239417597672117, 'learning_rate': 0.003960256235535713}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:39:20,749]\u001b[0m Trial 60 finished with value: 0.9718896150588989 and parameters: {'n_layers': 2, 'units': 371, 'dropout_rate': 0.2270557342037752, 'learning_rate': 0.002388458190813547}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:39:31,828]\u001b[0m Trial 61 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 364, 'dropout_rate': 0.19080370530209137, 'learning_rate': 0.005046913018960964}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:39:41,675]\u001b[0m Trial 62 finished with value: 0.9687662720680237 and parameters: {'n_layers': 3, 'units': 328, 'dropout_rate': 0.20361103535797842, 'learning_rate': 0.009806574880331272}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:39:54,081]\u001b[0m Trial 63 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 350, 'dropout_rate': 0.261080070035257, 'learning_rate': 0.003364398427877478}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:05,210]\u001b[0m Trial 64 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 485, 'dropout_rate': 0.16223333500178203, 'learning_rate': 0.005814053335919895}. Best is trial 12 with value: 0.9724102020263672.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:15,973]\u001b[0m Trial 65 finished with value: 0.9729307889938354 and parameters: {'n_layers': 3, 'units': 382, 'dropout_rate': 0.21992126546767482, 'learning_rate': 0.007985041750818492}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:26,958]\u001b[0m Trial 66 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 386, 'dropout_rate': 0.22282152076114187, 'learning_rate': 0.007582174005411509}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:38,065]\u001b[0m Trial 67 finished with value: 0.9682456851005554 and parameters: {'n_layers': 3, 'units': 248, 'dropout_rate': 0.23956249397798846, 'learning_rate': 0.008089947239885258}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:47,991]\u001b[0m Trial 68 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 415, 'dropout_rate': 0.2849676990848418, 'learning_rate': 0.004179106208606326}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:40:59,480]\u001b[0m Trial 69 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 325, 'dropout_rate': 0.25633580560270797, 'learning_rate': 0.005554069293908163}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:41:09,879]\u001b[0m Trial 70 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 298, 'dropout_rate': 0.183068576172652, 'learning_rate': 0.002888158335003439}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:41:20,973]\u001b[0m Trial 71 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 373, 'dropout_rate': 0.20262359278958778, 'learning_rate': 0.0058398844345551705}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:41:32,064]\u001b[0m Trial 72 finished with value: 0.9729307889938354 and parameters: {'n_layers': 3, 'units': 389, 'dropout_rate': 0.2201620045054424, 'learning_rate': 0.00799732484081675}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:41:41,669]\u001b[0m Trial 73 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 444, 'dropout_rate': 0.21646198165602132, 'learning_rate': 0.008393446849007549}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:41:53,144]\u001b[0m Trial 74 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 402, 'dropout_rate': 0.2488907874027039, 'learning_rate': 0.009854171170464112}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:42:15,186]\u001b[0m Trial 75 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 388, 'dropout_rate': 0.23738511447671498, 'learning_rate': 0.007011104391170627}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:42:26,112]\u001b[0m Trial 76 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 425, 'dropout_rate': 0.22134609758254112, 'learning_rate': 0.004485335823985257}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:42:36,972]\u001b[0m Trial 77 finished with value: 0.9604372978210449 and parameters: {'n_layers': 1, 'units': 341, 'dropout_rate': 0.2754830993378918, 'learning_rate': 0.0036936186358236017}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:42:46,816]\u001b[0m Trial 78 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 316, 'dropout_rate': 0.26500894334250075, 'learning_rate': 0.0064548247067111415}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:42:58,343]\u001b[0m Trial 79 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 354, 'dropout_rate': 0.1926016358830589, 'learning_rate': 0.00828205243129951}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:43:09,444]\u001b[0m Trial 80 finished with value: 0.9682456851005554 and parameters: {'n_layers': 3, 'units': 282, 'dropout_rate': 0.17363990870669613, 'learning_rate': 0.004849003484367606}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:43:20,532]\u001b[0m Trial 81 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 396, 'dropout_rate': 0.20506413003818455, 'learning_rate': 0.005737409664733563}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:43:31,620]\u001b[0m Trial 82 finished with value: 0.9698073863983154 and parameters: {'n_layers': 3, 'units': 367, 'dropout_rate': 0.19401829481440785, 'learning_rate': 0.006680233659932566}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:43:42,709]\u001b[0m Trial 83 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 63, 'dropout_rate': 0.21453979063215484, 'learning_rate': 0.008435781494002578}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:43:52,473]\u001b[0m Trial 84 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 377, 'dropout_rate': 0.1549400037746005, 'learning_rate': 0.003097046221143566}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:44:03,559]\u001b[0m Trial 85 finished with value: 0.9729307889938354 and parameters: {'n_layers': 3, 'units': 467, 'dropout_rate': 0.2354291469621266, 'learning_rate': 0.004058453829884552}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:44:14,652]\u001b[0m Trial 86 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 487, 'dropout_rate': 0.23581933282000564, 'learning_rate': 0.0022380957234152538}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:44:26,628]\u001b[0m Trial 87 finished with value: 0.9708485007286072 and parameters: {'n_layers': 3, 'units': 468, 'dropout_rate': 0.22974020821128718, 'learning_rate': 0.0036048186495817986}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:44:37,511]\u001b[0m Trial 88 finished with value: 0.9698073863983154 and parameters: {'n_layers': 3, 'units': 458, 'dropout_rate': 0.24882544488865074, 'learning_rate': 0.0046886257013002905}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:44:48,532]\u001b[0m Trial 89 finished with value: 0.9708485007286072 and parameters: {'n_layers': 2, 'units': 437, 'dropout_rate': 0.2567470247602927, 'learning_rate': 0.002729728300653647}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:00,034]\u001b[0m Trial 90 finished with value: 0.9661634564399719 and parameters: {'n_layers': 3, 'units': 494, 'dropout_rate': 0.21988509194333156, 'learning_rate': 0.007160557347713881}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:11,429]\u001b[0m Trial 91 finished with value: 0.9562727808952332 and parameters: {'n_layers': 3, 'units': 480, 'dropout_rate': 0.20867199956313232, 'learning_rate': 0.005338470631621072}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:22,212]\u001b[0m Trial 92 finished with value: 0.9692868590354919 and parameters: {'n_layers': 3, 'units': 417, 'dropout_rate': 0.18316275194937698, 'learning_rate': 0.00993878142245753}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:33,329]\u001b[0m Trial 93 finished with value: 0.9713690876960754 and parameters: {'n_layers': 3, 'units': 335, 'dropout_rate': 0.2317692672661073, 'learning_rate': 0.0038998486086391257}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:43,874]\u001b[0m Trial 94 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 448, 'dropout_rate': 0.2005460498894743, 'learning_rate': 0.008647929869798935}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:45:53,392]\u001b[0m Trial 95 finished with value: 0.9729307889938354 and parameters: {'n_layers': 3, 'units': 268, 'dropout_rate': 0.17650839084292397, 'learning_rate': 0.006329799848822065}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:46:04,520]\u001b[0m Trial 96 finished with value: 0.9698073863983154 and parameters: {'n_layers': 3, 'units': 263, 'dropout_rate': 0.24286679943234987, 'learning_rate': 0.006131003312959219}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:46:15,637]\u001b[0m Trial 97 finished with value: 0.9724102020263672 and parameters: {'n_layers': 3, 'units': 234, 'dropout_rate': 0.2710761195369018, 'learning_rate': 0.007138770523967417}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:46:37,747]\u001b[0m Trial 98 finished with value: 0.9703279733657837 and parameters: {'n_layers': 3, 'units': 268, 'dropout_rate': 0.26810524795844204, 'learning_rate': 0.007166622866334139}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "\u001b[32m[I 2023-05-08 20:46:48,967]\u001b[0m Trial 99 finished with value: 0.9718896150588989 and parameters: {'n_layers': 3, 'units': 246, 'dropout_rate': 0.28387757740452074, 'learning_rate': 0.008736507456386084}. Best is trial 65 with value: 0.9729307889938354.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'n_layers': 3, 'units': 382, 'dropout_rate': 0.21992126546767482, 'learning_rate': 0.007985041750818492}, Best value: 0.9729307889938354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna.visualization as viz\n",
        "\n",
        "# Plot the optimization history\n",
        "fig_opt = viz.plot_optimization_history(study)\n",
        "fig_opt.show()\n",
        "\n",
        "# Plot the importance of the hyperparameters\n",
        "fig_importance = viz.plot_param_importances(study)\n",
        "fig_importance.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WPV8V0RtDgQC",
        "outputId": "14e5d7ad-24c6-483f-c602-db693cdb8ed8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"ccb4880b-6400-4dbb-a944-6031038ffad7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ccb4880b-6400-4dbb-a944-6031038ffad7\")) {                    Plotly.newPlot(                        \"ccb4880b-6400-4dbb-a944-6031038ffad7\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.9614784121513367,0.9588755965232849,0.9703279733657837,0.9682456851005554,0.9708485007286072,0.9703279733657837,0.9708485007286072,0.9713690876960754,0.9593961238861084,0.9703279733657837,0.9692868590354919,0.9703279733657837,0.9724102020263672,0.9708485007286072,0.9703279733657837,0.9698073863983154,0.9703279733657837,0.9718896150588989,0.9567933082580566,0.9703279733657837,0.9724102020263672,0.9692868590354919,0.9718896150588989,0.9718896150588989,0.9703279733657837,0.9718896150588989,0.9718896150588989,0.9713690876960754,0.9708485007286072,0.9614784121513367,0.9713690876960754,0.9703279733657837,0.9692868590354919,0.9718896150588989,0.9703279733657837,0.9713690876960754,0.9713690876960754,0.9703279733657837,0.9713690876960754,0.9604372978210449,0.9713690876960754,0.9708485007286072,0.9703279733657837,0.9708485007286072,0.9718896150588989,0.9703279733657837,0.9703279733657837,0.9703279733657837,0.9708485007286072,0.9692868590354919,0.9718896150588989,0.9718896150588989,0.9713690876960754,0.9708485007286072,0.9718896150588989,0.9692868590354919,0.9698073863983154,0.9713690876960754,0.9682456851005554,0.9692868590354919,0.9718896150588989,0.9703279733657837,0.9687662720680237,0.9708485007286072,0.9703279733657837,0.9729307889938354,0.9708485007286072,0.9682456851005554,0.9708485007286072,0.9703279733657837,0.9713690876960754,0.9708485007286072,0.9729307889938354,0.9713690876960754,0.9703279733657837,0.9713690876960754,0.9718896150588989,0.9604372978210449,0.9718896150588989,0.9713690876960754,0.9682456851005554,0.9718896150588989,0.9698073863983154,0.9708485007286072,0.9692868590354919,0.9729307889938354,0.9703279733657837,0.9708485007286072,0.9698073863983154,0.9708485007286072,0.9661634564399719,0.9562727808952332,0.9692868590354919,0.9713690876960754,0.9703279733657837,0.9729307889938354,0.9698073863983154,0.9724102020263672,0.9703279733657837,0.9718896150588989],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.9614784121513367,0.9614784121513367,0.9703279733657837,0.9703279733657837,0.9708485007286072,0.9708485007286072,0.9708485007286072,0.9713690876960754,0.9713690876960754,0.9713690876960754,0.9713690876960754,0.9713690876960754,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9724102020263672,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354,0.9729307889938354],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ccb4880b-6400-4dbb-a944-6031038ffad7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"bae7ee1c-aea8-414e-8976-89b54414d171\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bae7ee1c-aea8-414e-8976-89b54414d171\")) {                    Plotly.newPlot(                        \"bae7ee1c-aea8-414e-8976-89b54414d171\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"learning_rate (FloatDistribution): 0.0036841558808858327<extra></extra>\",\"units (IntDistribution): 0.05187144640892294<extra></extra>\",\"dropout_rate (FloatDistribution): 0.152190807622694<extra></extra>\",\"n_layers (IntDistribution): 0.7922535900874972<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"0.05\",\"0.15\",\"0.79\"],\"textposition\":\"outside\",\"x\":[0.0036841558808858327,0.05187144640892294,0.152190807622694,0.7922535900874972],\"y\":[\"learning_rate\",\"units\",\"dropout_rate\",\"n_layers\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bae7ee1c-aea8-414e-8976-89b54414d171');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna-dashboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbmnAW0HIDRV",
        "outputId": "185c02b2-490a-42ec-9afe-47db7698c8cb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna-dashboard\n",
            "  Downloading optuna_dashboard-0.9.1-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (23.1)\n",
            "Collecting bottle\n",
            "  Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.2/90.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optuna>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (3.1.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.10.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (4.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.2)\n",
            "Installing collected packages: bottle, optuna-dashboard\n",
            "Successfully installed bottle-0.12.25 optuna-dashboard-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_optimization_history\n",
        "\n",
        "plot_optimization_history(study)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "s04uvvgjIh-5",
        "outputId": "ea0aaaf0-6471-4bc0-ca1c-75a3d6bbe99e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5b27fa5e-92a3-45e6-bb7f-4e08184e22a6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b27fa5e-92a3-45e6-bb7f-4e08184e22a6\")) {                    Plotly.newPlot(                        \"5b27fa5e-92a3-45e6-bb7f-4e08184e22a6\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1],\"y\":[0.9500260353088379,0.9698073863983154],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1],\"y\":[0.9500260353088379,0.9698073863983154],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5b27fa5e-92a3-45e6-bb7f-4e08184e22a6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_parallel_coordinate\n",
        "\n",
        "plot_parallel_coordinate(study)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "JY21OcfsItn5",
        "outputId": "53a80d79-14b1-4e68-9a4e-05540f441432"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"1d1641a5-acd8-4ae0-a9bd-122825b7e040\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d1641a5-acd8-4ae0-a9bd-122825b7e040\")) {                    Plotly.newPlot(                        \"1d1641a5-acd8-4ae0-a9bd-122825b7e040\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.9500260353088379,0.9698073863983154],\"values\":[0.9500260353088379,0.9698073863983154]},{\"label\":\"dropout_rate\",\"range\":[0.4044782184601774,0.4065619699025499],\"values\":[0.4044782184601774,0.4065619699025499]},{\"label\":\"learning_rate\",\"range\":[-3.7965019597747944,-3.664419325033022],\"ticktext\":[\"0.00016\",\"0.000217\"],\"tickvals\":[-3.7965019597747944,-3.664419325033022],\"values\":[-3.664419325033022,-3.7965019597747944]},{\"label\":\"n_layers\",\"range\":[1,3],\"values\":[1,3]},{\"label\":\"units\",\"range\":[167,232],\"values\":[167,232]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.9500260353088379,0.9698073863983154],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1d1641a5-acd8-4ae0-a9bd-122825b7e040');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def objective(trial):\n",
        "#     # create the model\n",
        "#     model = create_model(trial)\n",
        "\n",
        "#     # train the model\n",
        "#     history = model.fit(train_feature_trans, epochs=10, validation_data=train_label)\n",
        "\n",
        "#     # evaluate the model on the testing set and return the metric to optimize\n",
        "#     return history.history['val_accuracy'][-1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MN20PoaAAEdV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# print the best hyperparameters and the value of the metric to optimize\n",
        "best_params = study.best_params\n",
        "best_value = study.best_value\n",
        "print(f\"Best params: {best_params}, Best value: {best_value}\")\n"
      ],
      "metadata": {
        "id": "Xc1oKh1HAsaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with the best hyperparameters\n",
        "best_model = create_model(study.best_params)\n",
        "\n",
        "# train the model on the entire training set\n",
        "history = best_model.fit(train_ds, epochs=10, validation_data=test_ds)\n",
        "\n",
        "# plot the accuracy and loss curves\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history\n"
      ],
      "metadata": {
        "id": "3SDdkeySAuTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}